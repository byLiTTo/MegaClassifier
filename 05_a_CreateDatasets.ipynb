{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from itables import init_notebook_mode\n",
    "\n",
    "init_notebook_mode(all_interactive=True)\n",
    "\n",
    "required_paths = [\"/ai4eutils\", \"/CameraTraps\", \"/yolov5\"]\n",
    "python_path = os.environ.get(\"PYTHONPATH\", \"\")\n",
    "root_path = os.getcwd()\n",
    "\n",
    "for path in required_paths:\n",
    "    if not any(p.endswith(path) for p in python_path.split(\":\")):\n",
    "        python_path += f\":{root_path}/data/external{path}\"\n",
    "\n",
    "os.environ[\"PYTHONPATH\"] = python_path"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DATASET_NAME = \"onlyDetectionsForTrain\"\n",
    "\n",
    "DATASET_FOLDER = os.path.abspath(\"./data/processed\")\n",
    "DATASET_PATH = os.path.join(DATASET_FOLDER, DATASET_NAME)\n",
    "\n",
    "ORIGINAL_PATH = os.path.abspath(\"./resources/fit_images/0_003\")\n",
    "\n",
    "IMAGES_CSV = os.path.abspath(\n",
    "    \"resources/megadetector_coverage/MegaDetector_0_003.csv\"\n",
    ")\n",
    "\n",
    "dataset = pd.read_csv(IMAGES_CSV, sep=\";\")\n",
    "\n",
    "new_dataset = pd.DataFrame({})\n",
    "\n",
    "for index in tqdm.tqdm(dataset.index):\n",
    "    subset = dataset.loc[index, \"subset\"]\n",
    "    detector_label = dataset.loc[index, \"detector_label\"]\n",
    "\n",
    "    if subset == \"train\" and detector_label == 0:\n",
    "        continue\n",
    "    else:\n",
    "        file_name = dataset.loc[index, \"file_name\"]\n",
    "        label = dataset.loc[index, \"label\"]\n",
    "        binary_label = dataset.loc[index, \"binary_label\"]\n",
    "\n",
    "        new_row = {\n",
    "            \"file_name\": file_name,\n",
    "            \"label\": label,\n",
    "            \"binary_label\": binary_label,\n",
    "            \"detector_label\": detector_label,\n",
    "            \"subset\": subset\n",
    "        }\n",
    "        new_dataset = pd.concat([new_dataset, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "        original_file = os.path.join(ORIGINAL_PATH, file_name)\n",
    "        new_file = os.path.join(DATASET_PATH, file_name)\n",
    "        os.makedirs(os.path.dirname(new_file), exist_ok=True)\n",
    "        try:\n",
    "            shutil.copy(original_file, new_file)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File {original_file} not found.\")\n",
    "new_dataset.to_csv(os.path.join(DATASET_PATH, f\"{DATASET_NAME}.csv\"), index=False, sep=\";\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DATASET_NAME = \"emptyOriginalAnimalDetection\"\n",
    "\n",
    "DATASET_FOLDER = os.path.abspath(\"./data/processed\")\n",
    "DATASET_PATH = os.path.join(DATASET_FOLDER, DATASET_NAME)\n",
    "\n",
    "FIT_IMAGES_PATH = os.path.abspath(\"./resources/fit_images/0_003\")\n",
    "ORIGINAL_PATH = os.path.abspath(\"./data/interim/emptyNonEmptyDataset\")\n",
    "\n",
    "IMAGES_CSV = os.path.abspath(\n",
    "    \"resources/megadetector_coverage/MegaDetector_0_003.csv\"\n",
    ")\n",
    "\n",
    "dataset = pd.read_csv(IMAGES_CSV, sep=\";\")\n",
    "\n",
    "new_dataset = pd.DataFrame({})\n",
    "\n",
    "for index in tqdm.tqdm(dataset.index):\n",
    "    file_name = dataset.loc[index, \"file_name\"]\n",
    "    label = dataset.loc[index, \"label\"]\n",
    "    binary_label = dataset.loc[index, \"binary_label\"]\n",
    "    detector_label = dataset.loc[index, \"detector_label\"]\n",
    "    subset = dataset.loc[index, \"subset\"]\n",
    "\n",
    "    new_row = {\n",
    "        \"file_name\": file_name,\n",
    "        \"label\": label,\n",
    "        \"binary_label\": binary_label,\n",
    "        \"detector_label\": detector_label,\n",
    "        \"subset\": subset\n",
    "    }\n",
    "    new_dataset = pd.concat([new_dataset, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    if detector_label == 0:\n",
    "        original_file = os.path.join(ORIGINAL_PATH, file_name)\n",
    "    else:\n",
    "        original_file = os.path.join(FIT_IMAGES_PATH, file_name)\n",
    "\n",
    "    new_file = os.path.join(DATASET_PATH, file_name)\n",
    "    os.makedirs(os.path.dirname(new_file), exist_ok=True)\n",
    "    try:\n",
    "        shutil.copy(original_file, new_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {original_file} not found.\")\n",
    "\n",
    "new_dataset.to_csv(os.path.join(DATASET_PATH, f\"{DATASET_NAME}.csv\"), index=False, sep=\";\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DATASET_NAME = \"emptyNonEmptyDataset\"\n",
    "\n",
    "DATASET_FOLDER = os.path.abspath(\"./data/processed\")\n",
    "DATASET_PATH = os.path.join(DATASET_FOLDER, DATASET_NAME)\n",
    "\n",
    "ORIGINAL_PATH = os.path.abspath(\"./data/interim/emptyNonEmptyDataset\")\n",
    "\n",
    "IMAGES_CSV = os.path.abspath(\n",
    "    \"resources/megadetector_coverage/MegaDetector_0_003.csv\"\n",
    ")\n",
    "\n",
    "dataset = pd.read_csv(IMAGES_CSV, sep=\";\")\n",
    "\n",
    "new_dataset = pd.DataFrame({})\n",
    "\n",
    "for index in tqdm.tqdm(dataset.index):\n",
    "    file_name = dataset.loc[index, \"file_name\"]\n",
    "    label = dataset.loc[index, \"label\"]\n",
    "    binary_label = dataset.loc[index, \"binary_label\"]\n",
    "    detector_label = dataset.loc[index, \"detector_label\"]\n",
    "    subset = dataset.loc[index, \"subset\"]\n",
    "\n",
    "    new_row = {\n",
    "        \"file_name\": file_name,\n",
    "        \"label\": label,\n",
    "        \"binary_label\": binary_label,\n",
    "        \"detector_label\": detector_label,\n",
    "        \"subset\": subset\n",
    "    }\n",
    "    new_dataset = pd.concat([new_dataset, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    original_file = os.path.join(ORIGINAL_PATH, file_name)\n",
    "    new_file = os.path.join(DATASET_PATH, file_name)\n",
    "    os.makedirs(os.path.dirname(new_file), exist_ok=True)\n",
    "    try:\n",
    "        shutil.copy(original_file, new_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {original_file} not found.\")\n",
    "\n",
    "new_dataset.to_csv(os.path.join(DATASET_PATH, f\"{DATASET_NAME}.csv\"), index=False, sep=\";\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TFG] *",
   "language": "python",
   "name": "conda-env-TFG-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
