{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/litto/miniconda/envs/TFG/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import src.model as models\n",
    "from sklearn.metrics import auc, confusion_matrix, roc_curve\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.metrics import AUC, BinaryAccuracy, Precision, Recall\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import src.graphics as graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = \"3\"\n",
    "MODEL_BASE_NAME = \"MegaClassifier_a_MobileNetV2\"\n",
    "\n",
    "DATASET_CSV = os.path.abspath(\n",
    "    \"./data/processed/onlyDetectionsForTrain/onlyDetectionsForTrain.csv\"\n",
    ")\n",
    "DATASET_PATH = os.path.dirname(DATASET_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(DATASET_CSV, sep=\";\")\n",
    "dataset[\"file_name\"] = dataset[\"file_name\"].apply(\n",
    "    lambda x: os.path.join(DATASET_PATH, x)\n",
    ")\n",
    "dataset[\"binary_label\"] = dataset[\"binary_label\"].astype(str)\n",
    "\n",
    "train_dataset = dataset[dataset[\"subset\"] == \"train\"]\n",
    "validationtrain_dataset = dataset[dataset[\"subset\"] == \"validation\"]\n",
    "test_dataset = dataset[dataset[\"subset\"] == \"test\"]\n",
    "\n",
    "EPOCHS = 10\n",
    "IMAGE_SIZE = (224, 224)\n",
    "IMAGE_SHAPE = IMAGE_SIZE + (3,)\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZERS = {\n",
    "    \"Adam\": tf.keras.optimizers.legacy.Adam(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS = {\n",
    "    \"BinaryFocalCrossentropy\": lambda x, y: tf.keras.losses.BinaryFocalCrossentropy(\n",
    "        alpha=x, gamma=y\n",
    "    ),\n",
    "}\n",
    "\n",
    "ALPHAS = [0.25, 0.5, 0.75]\n",
    "\n",
    "GAMMAS = [0.0, 1.0, 2.0, 3.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 16:41:13.715755: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
      "2025-03-01 16:41:13.715782: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-03-01 16:41:13.715788: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-03-01 16:41:13.715813: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-03-01 16:41:13.715826: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "METRICS = [\n",
    "    BinaryAccuracy(name=\"accuracy\"),\n",
    "    Precision(name=\"precision\"),\n",
    "    Recall(name=\"recall\"),\n",
    "    AUC(name=\"auc\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17906 validated image filenames belonging to 2 classes.\n",
      "Found 4286 validated image filenames belonging to 2 classes.\n",
      "Found 4286 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 16:41:15.651875: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - ETA: 0s - loss: 0.2567 - accuracy: 0.8867 - precision: 0.9090 - recall: 0.9409 - auc: 0.9480"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 16:42:08.502655: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - 65s 229ms/step - loss: 0.2567 - accuracy: 0.8867 - precision: 0.9090 - recall: 0.9409 - auc: 0.9480 - val_loss: 0.1990 - val_accuracy: 0.9188 - val_precision: 0.9353 - val_recall: 0.9425 - val_auc: 0.9738\n",
      "Epoch 2/10\n",
      "280/280 [==============================] - 57s 204ms/step - loss: 0.2014 - accuracy: 0.9163 - precision: 0.9404 - recall: 0.9468 - auc: 0.9678 - val_loss: 0.1867 - val_accuracy: 0.9239 - val_precision: 0.9343 - val_recall: 0.9520 - val_auc: 0.9770\n",
      "Epoch 3/10\n",
      "280/280 [==============================] - 57s 204ms/step - loss: 0.1877 - accuracy: 0.9208 - precision: 0.9448 - recall: 0.9481 - auc: 0.9722 - val_loss: 0.1794 - val_accuracy: 0.9263 - val_precision: 0.9465 - val_recall: 0.9418 - val_auc: 0.9784\n",
      "Epoch 4/10\n",
      "280/280 [==============================] - 59s 210ms/step - loss: 0.1801 - accuracy: 0.9254 - precision: 0.9487 - recall: 0.9505 - auc: 0.9745 - val_loss: 0.1760 - val_accuracy: 0.9288 - val_precision: 0.9448 - val_recall: 0.9478 - val_auc: 0.9790\n",
      "Epoch 5/10\n",
      "280/280 [==============================] - 59s 212ms/step - loss: 0.1746 - accuracy: 0.9267 - precision: 0.9495 - recall: 0.9514 - auc: 0.9758 - val_loss: 0.1771 - val_accuracy: 0.9286 - val_precision: 0.9362 - val_recall: 0.9573 - val_auc: 0.9791\n",
      "Epoch 6/10\n",
      "280/280 [==============================] - 57s 204ms/step - loss: 0.1701 - accuracy: 0.9299 - precision: 0.9518 - recall: 0.9534 - auc: 0.9771 - val_loss: 0.1824 - val_accuracy: 0.9235 - val_precision: 0.9222 - val_recall: 0.9658 - val_auc: 0.9792\n",
      "Epoch 7/10\n",
      "280/280 [==============================] - 57s 203ms/step - loss: nan - accuracy: 0.8102 - precision: 0.9525 - recall: 0.7821 - auc: 0.8517 - val_loss: nan - val_accuracy: 0.3383 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 8/10\n",
      "280/280 [==============================] - 57s 204ms/step - loss: nan - accuracy: 0.2611 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: nan - val_accuracy: 0.3383 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 9/10\n",
      "280/280 [==============================] - 57s 204ms/step - loss: nan - accuracy: 0.2611 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: nan - val_accuracy: 0.3383 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 10/10\n",
      "280/280 [==============================] - 58s 206ms/step - loss: nan - accuracy: 0.2611 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: nan - val_accuracy: 0.3383 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n",
      "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n",
      "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/litto/WORKSPACE/MegaClassifier/models/MegaClassifier_a_MobileNetV2/v4/v4.0.0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/litto/WORKSPACE/MegaClassifier/models/MegaClassifier_a_MobileNetV2/v4/v4.0.0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 11s 168ms/step - loss: nan - accuracy: 0.3383 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 16:51:16.143155: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 11s 160ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 131\u001b[0m\n\u001b[1;32m    128\u001b[0m y_pred_prob \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_images)\n\u001b[1;32m    129\u001b[0m y_true \u001b[38;5;241m=\u001b[39m test_images\u001b[38;5;241m.\u001b[39mlabels\n\u001b[0;32m--> 131\u001b[0m fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_prob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m auc(fpr, tpr)\n\u001b[1;32m    134\u001b[0m roc_curve_chart \u001b[38;5;241m=\u001b[39m graphics\u001b[38;5;241m.\u001b[39mcreate_roc_curve_chart(\n\u001b[1;32m    135\u001b[0m     fpr\u001b[38;5;241m=\u001b[39mfpr,\n\u001b[1;32m    136\u001b[0m     tpr\u001b[38;5;241m=\u001b[39mtpr,\n\u001b[1;32m    137\u001b[0m     roc_auc\u001b[38;5;241m=\u001b[39mroc_auc,\n\u001b[1;32m    138\u001b[0m     model_name\u001b[38;5;241m=\u001b[39mMODEL_COMPLETE_NAME,\n\u001b[1;32m    139\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda/envs/TFG/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda/envs/TFG/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1094\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    993\u001b[0m     {\n\u001b[1;32m    994\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m ):\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m \n\u001b[1;32m   1007\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;124;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1094\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda/envs/TFG/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:809\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    807\u001b[0m y_score \u001b[38;5;241m=\u001b[39m column_or_1d(y_score)\n\u001b[1;32m    808\u001b[0m assert_all_finite(y_true)\n\u001b[0;32m--> 809\u001b[0m \u001b[43massert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;66;03m# Filter out zero-weighted samples, as they should not impact the result\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/envs/TFG/lib/python3.8/site-packages/sklearn/utils/validation.py:202\u001b[0m, in \u001b[0;36massert_all_finite\u001b[0;34m(X, allow_nan, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massert_all_finite\u001b[39m(\n\u001b[1;32m    177\u001b[0m     X,\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    182\u001b[0m ):\n\u001b[1;32m    183\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Throw a ValueError if X contains NaN or infinity.\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m        documentation.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/TFG/lib/python3.8/site-packages/sklearn/utils/validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/TFG/lib/python3.8/site-packages/sklearn/utils/validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m     )\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "SUBVERSION = 0\n",
    "SUB_SUBVERSION = 0\n",
    "\n",
    "for ALPHA in ALPHAS:\n",
    "    for GAMMA in GAMMAS:\n",
    "        LOGS_PATH = os.path.abspath(\n",
    "            f\"./logs/{MODEL_BASE_NAME}/v{VERSION}/v{VERSION}.{SUBVERSION}.{SUB_SUBVERSION}\"\n",
    "        )\n",
    "        MODELS_PATH = os.path.abspath(\n",
    "            f\"./models/{MODEL_BASE_NAME}/v{VERSION}/v{VERSION}.{SUBVERSION}.{SUB_SUBVERSION}\"\n",
    "        )\n",
    "        REPORTS_PATH = os.path.abspath(\n",
    "            f\"./reports/{MODEL_BASE_NAME}/v{VERSION}/v{VERSION}.{SUBVERSION}.{SUB_SUBVERSION}\"\n",
    "        )\n",
    "\n",
    "        MODEL_COMPLETE_NAME = (\n",
    "            f\"{MODEL_BASE_NAME} v{VERSION}.{SUBVERSION}.{SUB_SUBVERSION}\"\n",
    "        )\n",
    "\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "        )\n",
    "        train_images = train_datagen.flow_from_dataframe(\n",
    "            dataframe=train_dataset,\n",
    "            x_col=\"file_name\",\n",
    "            y_col=\"binary_label\",\n",
    "            target_size=IMAGE_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode=\"binary\",\n",
    "            shuffle=True,\n",
    "            seed=SEED,\n",
    "        )\n",
    "\n",
    "        datagen = ImageDataGenerator(\n",
    "            preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "        )\n",
    "        validation_images = datagen.flow_from_dataframe(\n",
    "            dataframe=validationtrain_dataset,\n",
    "            x_col=\"file_name\",\n",
    "            y_col=\"binary_label\",\n",
    "            target_size=IMAGE_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode=\"binary\",\n",
    "            shuffle=True,\n",
    "            seed=SEED,\n",
    "        )\n",
    "        test_images = datagen.flow_from_dataframe(\n",
    "            dataframe=test_dataset,\n",
    "            x_col=\"file_name\",\n",
    "            y_col=\"binary_label\",\n",
    "            target_size=IMAGE_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode=\"binary\",\n",
    "            shuffle=False,\n",
    "            seed=SEED,\n",
    "        )\n",
    "\n",
    "        pretrained_model = tf.keras.applications.MobileNetV2(\n",
    "            weights=\"imagenet\",\n",
    "            include_top=False,\n",
    "            input_shape=IMAGE_SHAPE,\n",
    "        )\n",
    "        pretrained_model.trainable = False\n",
    "\n",
    "        model = tf.keras.Sequential(\n",
    "            [\n",
    "                pretrained_model,\n",
    "                tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "            ],\n",
    "            name=f\"{MODEL_BASE_NAME}_v{VERSION}.{SUBVERSION}.{SUB_SUBVERSION}\",\n",
    "        )\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=OPTIMIZERS[\"RMSprop\"],\n",
    "            loss=LOSS[\"BinaryFocalCrossentropy\"](ALPHA, GAMMA),\n",
    "            metrics=METRICS,\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            train_images,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=validation_images,\n",
    "            callbacks=[TensorBoard(log_dir=LOGS_PATH)],\n",
    "        )\n",
    "\n",
    "        dataframe = pd.DataFrame(history.history)\n",
    "        history_path = os.path.join(\n",
    "            LOGS_PATH, f\"history_v{VERSION}.{SUBVERSION}.{SUB_SUBVERSION}.csv\"\n",
    "        )\n",
    "        dataframe.to_csv(history_path, sep=\";\", index=False)\n",
    "\n",
    "        os.makedirs(REPORTS_PATH, exist_ok=True)\n",
    "        accuracy_chart = graphics.create_training_accuracy_chart(\n",
    "            history_path=history_path,\n",
    "            model_name=MODEL_COMPLETE_NAME,\n",
    "        )\n",
    "        accuracy_chart.write_image(\n",
    "            f\"{REPORTS_PATH}/accuracy_v{VERSION}.{SUBVERSION}.{SUB_SUBVERSION}.png\"\n",
    "        )\n",
    "\n",
    "        loss_chart = graphics.create_training_loss_chart(\n",
    "            history_path=history_path,\n",
    "            model_name=MODEL_COMPLETE_NAME,\n",
    "        )\n",
    "        loss_chart.write_image(\n",
    "            f\"{REPORTS_PATH}/loss_v{VERSION}.{SUBVERSION}.{SUB_SUBVERSION}.png\"\n",
    "        )\n",
    "\n",
    "        os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "        model.save(MODELS_PATH)\n",
    "\n",
    "        results = model.evaluate(test_images)\n",
    "        metric_names = history.model.metrics_names\n",
    "        evaluation_results = {\n",
    "            (\"test_\" + name): value for name, value in zip(metric_names, results)\n",
    "        }\n",
    "\n",
    "        evaluation = pd.DataFrame([evaluation_results])\n",
    "        evaluation.to_csv(\n",
    "            os.path.join(\n",
    "                LOGS_PATH, f\"evaluation_v{VERSION}.{SUBVERSION}.{SUB_SUBVERSION}.csv\"\n",
    "            ),\n",
    "            sep=\";\",\n",
    "            index=False,\n",
    "        )\n",
    "\n",
    "        y_pred_prob = model.predict(test_images)\n",
    "        y_true = test_images.labels\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        roc_curve_chart = graphics.create_roc_curve_chart(\n",
    "            fpr=fpr,\n",
    "            tpr=tpr,\n",
    "            roc_auc=roc_auc,\n",
    "            model_name=MODEL_COMPLETE_NAME,\n",
    "        )\n",
    "        roc_curve_chart.write_image(\n",
    "            f\"{REPORTS_PATH}/roc_curve_v{VERSION}.{SUBVERSION}.{SUB_SUBVERSION}.png\"\n",
    "        )\n",
    "\n",
    "        optimal_idx = np.argmax(tpr - fpr)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "        y_pred_class = (y_pred_prob > optimal_threshold).astype(int)\n",
    "        conf_matrix = confusion_matrix(y_true, y_pred_class)\n",
    "        conf_matrix_text = [[str(value) for value in row] for row in conf_matrix]\n",
    "\n",
    "        confusion_matrix_chart = graphics.create_confusion_matrix_chart(\n",
    "            conf_matrix=conf_matrix,\n",
    "            conf_matrix_text=conf_matrix_text,\n",
    "            model_name=MODEL_COMPLETE_NAME,\n",
    "        )\n",
    "        confusion_matrix_chart.write_image(\n",
    "            f\"{REPORTS_PATH}/confusion_matrix_optimal_v{VERSION}.{SUBVERSION}.{SUB_SUBVERSION}.png\"\n",
    "        )\n",
    "\n",
    "        y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
    "        conf_matrix = confusion_matrix(y_true, y_pred_class)\n",
    "        conf_matrix_text = [[str(value) for value in row] for row in conf_matrix]\n",
    "\n",
    "        confusion_matrix_chart = graphics.create_confusion_matrix_chart(\n",
    "            conf_matrix=conf_matrix,\n",
    "            conf_matrix_text=conf_matrix_text,\n",
    "            model_name=MODEL_COMPLETE_NAME,\n",
    "        )\n",
    "        confusion_matrix_chart.write_image(\n",
    "            f\"{REPORTS_PATH}/confusion_matrix_v{VERSION}.{SUBVERSION}.{SUB_SUBVERSION}.png\"\n",
    "        )\n",
    "\n",
    "        SUB_SUBVERSION += 1\n",
    "\n",
    "    SUBVERSION += 1\n",
    "    print(\"\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
