{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "import src.data.Dataset as dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itables import init_notebook_mode\n",
    "\n",
    "init_notebook_mode(all_interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM_PATH = os.path.abspath(\"./data/raw/emptyNonEmptyDataset\")\n",
    "RAW_DATASET = os.path.abspath(\"./data/raw/emptyNonEmptyDataset/10000Images.csv\")\n",
    "\n",
    "TO_PATH = os.path.join(os.path.abspath(\"./data/interim/\"), os.path.basename(FROM_PATH))\n",
    "\n",
    "\n",
    "print(f\"FROM_PATH:   {FROM_PATH}\")\n",
    "print(f\"TO_PATH:     {TO_PATH}\")\n",
    "print(f\"RAW_DATASET: {RAW_DATASET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_original = dt.load_from_csv(RAW_DATASET)\n",
    "dataset_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = len(dataset_original[\"file_name\"])\n",
    "print(f\"Number of images in dataset: {num_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_routes = dataset_original[\"file_name\"].duplicated().sum()\n",
    "print(f\"Number of duplicate routes: {duplicate_routes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_without_duplicates = dataset_original.drop_duplicates(subset=\"file_name\")\n",
    "dataset_without_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = dataset_without_duplicates[\"label\"].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cleaned = dataset_without_duplicates[\n",
    "    dataset_without_duplicates[\"label\"] != \"dudosa\"\n",
    "]\n",
    "dataset_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cleaned = dataset_cleaned.copy()\n",
    "dataset_cleaned[\"binary_label\"] = dataset_cleaned[\"label\"].apply(\n",
    "    lambda x: \"0\" if x == \"vacia\" else \"1\"\n",
    ")\n",
    "\n",
    "dataset_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = dataset_cleaned[\"binary_label\"].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_images_processed = 0\n",
    "total_images_copied = 0\n",
    "\n",
    "filtered_dataset = pd.DataFrame({}, columns=dataset_cleaned.columns)\n",
    "\n",
    "for _, row in tqdm.tqdm(dataset_cleaned.iterrows()):\n",
    "    file_name = row[\"file_name\"].replace(\"\\\\\", \"/\")\n",
    "\n",
    "    original_file = os.path.join(FROM_PATH, file_name[1:])\n",
    "\n",
    "    filtered_file = file_name.replace(\"(\", \"_\")\n",
    "    filtered_file = filtered_file.replace(\")\", \"_\")\n",
    "    filtered_file = (\n",
    "        filtered_file.replace(\"á\", \"a\")\n",
    "        .replace(\"Á\", \"A\")\n",
    "        .replace(\"é\", \"e\")\n",
    "        .replace(\"É\", \"E\")\n",
    "        .replace(\"í\", \"i\")\n",
    "        .replace(\"Í\", \"I\")\n",
    "        .replace(\"ó\", \"o\")\n",
    "        .replace(\"Ó\", \"O\")\n",
    "        .replace(\"ú\", \"u\")\n",
    "        .replace(\"Ú\", \"U\")\n",
    "    )\n",
    "    filtered_file = filtered_file.replace(\"ñ\", \"n\").replace(\"Ñ\", \"N\")\n",
    "\n",
    "    new_row = pd.DataFrame(\n",
    "        {\n",
    "            \"file_name\": [filtered_file[1:]],\n",
    "            \"label\": [row[\"label\"]],\n",
    "            \"binary_label\": [row[\"binary_label\"]],\n",
    "        }\n",
    "    )\n",
    "    filtered_dataset = pd.concat([filtered_dataset, new_row], ignore_index=True)\n",
    "\n",
    "    filtered_file = os.path.join(TO_PATH, filtered_file[1:])\n",
    "    os.makedirs(os.path.dirname(filtered_file), exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        shutil.copyfile(original_file, filtered_file)\n",
    "        total_images_copied += 1\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {original_file}\")\n",
    "\n",
    "\n",
    "number_samples = len(filtered_dataset)\n",
    "print(f\"Number of samples: {number_samples}\")\n",
    "\n",
    "dt.dataset_to_csv(\n",
    "    filtered_dataset, (TO_PATH + \"/\" + str(number_samples) + \"Images_binary.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
