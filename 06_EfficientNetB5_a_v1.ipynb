{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"oQUZPTyG9M55","executionInfo":{"status":"ok","timestamp":1742677037286,"user_tz":-60,"elapsed":3818,"user":{"displayName":"Carlos García Silva","userId":"10388926223905764529"}}},"outputs":[],"source":["import os\n","\n","import numpy as np\n","import pandas as pd\n","import zipfile\n","import tensorflow as tf\n","import shutil\n","from sklearn.metrics import auc, confusion_matrix, roc_curve\n","from tensorflow.keras.callbacks import TensorBoard\n","from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall, AUC\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","BASE_PATH = os.path.abspath(\"./drive/MyDrive/MegaClassifier\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ua_x2H2FbfFz","executionInfo":{"status":"ok","timestamp":1742677070380,"user_tz":-60,"elapsed":33092,"user":{"displayName":"Carlos García Silva","userId":"10388926223905764529"}},"outputId":"06b55fc7-e3d9-40c3-b7d4-58bf6b5a06a1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["MODEL_NAME = \"MegaClassifier_a\"\n","VERSION = \"v1\""],"metadata":{"id":"YMZgeVIKTZiH","executionInfo":{"status":"ok","timestamp":1742677070420,"user_tz":-60,"elapsed":31,"user":{"displayName":"Carlos García Silva","userId":"10388926223905764529"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["DATASETS = {\n","    \"MegaClassifier_a\": \"onlyDetectionsForTrain\",\n","    \"MegaClassifier_b\": \"emptyOriginalAnimalDetection\",\n","    \"MegaClassifier_c\": \"emptyNonEmptyDataset\",\n","}"],"metadata":{"id":"ZB4MppQXbn2q","executionInfo":{"status":"ok","timestamp":1742677070422,"user_tz":-60,"elapsed":1,"user":{"displayName":"Carlos García Silva","userId":"10388926223905764529"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":12897,"status":"ok","timestamp":1742677083319,"user":{"displayName":"Carlos García Silva","userId":"10388926223905764529"},"user_tz":-60},"id":"1dW32L-3-Y3S"},"outputs":[],"source":["DATASET_PATH_ZIP = os.path.join(BASE_PATH, f\"data/processed/{DATASETS[MODEL_NAME]}.zip\")\n","with zipfile.ZipFile(DATASET_PATH_ZIP, 'r') as zip_ref:\n","      zip_ref.extractall(\"./data/processed\")\n","DATASET_DIR = os.path.abspath(f\"data/processed/{DATASETS[MODEL_NAME]}\")"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"_pThgKSR9M58","executionInfo":{"status":"ok","timestamp":1742677083341,"user_tz":-60,"elapsed":4,"user":{"displayName":"Carlos García Silva","userId":"10388926223905764529"}}},"outputs":[],"source":["EPOCHS = 10\n","\n","IMAGE_SIZE = (456, 456)\n","IMAGE_SHAPE = IMAGE_SIZE + (3,)\n","SEED = 42"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H5EH-u2Q9M5-","outputId":"13b28e44-5b5d-43d4-a5d6-786806235bb4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 17906 images belonging to 2 classes.\n","Found 4286 images belonging to 2 classes.\n","Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb5_notop.h5\n","\u001b[1m115263384/115263384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 156ms/step - accuracy: 0.8780 - auc: 0.9336 - loss: 0.2824 - precision: 0.9171 - recall: 0.9187 - val_accuracy: 0.9379 - val_auc: 0.9830 - val_loss: 0.1616 - val_precision: 0.9704 - val_recall: 0.9348\n","Epoch 2/10\n","\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 94ms/step - accuracy: 0.9404 - auc: 0.9826 - loss: 0.1523 - precision: 0.9637 - recall: 0.9556 - val_accuracy: 0.9452 - val_auc: 0.9862 - val_loss: 0.1424 - val_precision: 0.9676 - val_recall: 0.9489\n","Epoch 3/10\n","\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 94ms/step - accuracy: 0.9410 - auc: 0.9844 - loss: 0.1424 - precision: 0.9648 - recall: 0.9553 - val_accuracy: 0.9487 - val_auc: 0.9866 - val_loss: 0.1382 - val_precision: 0.9681 - val_recall: 0.9538\n","Epoch 4/10\n","\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 94ms/step - accuracy: 0.9477 - auc: 0.9859 - loss: 0.1346 - precision: 0.9679 - recall: 0.9609 - val_accuracy: 0.9477 - val_auc: 0.9872 - val_loss: 0.1374 - val_precision: 0.9586 - val_recall: 0.9626\n","Epoch 5/10\n","\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 94ms/step - accuracy: 0.9476 - auc: 0.9877 - loss: 0.1274 - precision: 0.9676 - recall: 0.9611 - val_accuracy: 0.9498 - val_auc: 0.9879 - val_loss: 0.1322 - val_precision: 0.9603 - val_recall: 0.9640\n","Epoch 6/10\n","\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 94ms/step - accuracy: 0.9481 - auc: 0.9872 - loss: 0.1282 - precision: 0.9679 - recall: 0.9615 - val_accuracy: 0.9491 - val_auc: 0.9880 - val_loss: 0.1316 - val_precision: 0.9596 - val_recall: 0.9637\n","Epoch 7/10\n","\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 95ms/step - accuracy: 0.9478 - auc: 0.9882 - loss: 0.1237 - precision: 0.9663 - recall: 0.9625 - val_accuracy: 0.9533 - val_auc: 0.9886 - val_loss: 0.1257 - val_precision: 0.9694 - val_recall: 0.9598\n","Epoch 8/10\n","\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 94ms/step - accuracy: 0.9525 - auc: 0.9889 - loss: 0.1194 - precision: 0.9707 - recall: 0.9645 - val_accuracy: 0.9501 - val_auc: 0.9886 - val_loss: 0.1272 - val_precision: 0.9733 - val_recall: 0.9506\n","Epoch 9/10\n","\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 94ms/step - accuracy: 0.9538 - auc: 0.9891 - loss: 0.1177 - precision: 0.9706 - recall: 0.9673 - val_accuracy: 0.9517 - val_auc: 0.9879 - val_loss: 0.1267 - val_precision: 0.9611 - val_recall: 0.9661\n","Epoch 10/10\n","\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 93ms/step - accuracy: 0.9522 - auc: 0.9890 - loss: 0.1188 - precision: 0.9720 - recall: 0.9629 - val_accuracy: 0.9517 - val_auc: 0.9884 - val_loss: 0.1251 - val_precision: 0.9617 - val_recall: 0.9654\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Found 17906 images belonging to 2 classes.\n","Found 4286 images belonging to 2 classes.\n","Epoch 1/10\n","\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 353ms/step - accuracy: 0.8809 - auc: 0.9364 - loss: 0.2944 - precision: 0.9098 - recall: 0.9316 - val_accuracy: 0.9370 - val_auc: 0.9811 - val_loss: 0.1709 - val_precision: 0.9582 - val_recall: 0.9461\n","Epoch 2/10\n","\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 186ms/step - accuracy: 0.9344 - auc: 0.9789 - loss: 0.1682 - precision: 0.9594 - recall: 0.9520 - val_accuracy: 0.9440 - val_auc: 0.9849 - val_loss: 0.1511 - val_precision: 0.9639 - val_recall: 0.9510\n","Epoch 3/10\n","\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 186ms/step - accuracy: 0.9416 - auc: 0.9838 - loss: 0.1473 - precision: 0.9634 - recall: 0.9575 - val_accuracy: 0.9468 - val_auc: 0.9858 - val_loss: 0.1440 - val_precision: 0.9681 - val_recall: 0.9510\n","Epoch 4/10\n","\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 187ms/step - accuracy: 0.9417 - auc: 0.9846 - loss: 0.1435 - precision: 0.9631 - recall: 0.9575 - val_accuracy: 0.9475 - val_auc: 0.9865 - val_loss: 0.1381 - val_precision: 0.9708 - val_recall: 0.9492\n","Epoch 5/10\n","\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 189ms/step - accuracy: 0.9432 - auc: 0.9857 - loss: 0.1368 - precision: 0.9663 - recall: 0.9567 - val_accuracy: 0.9463 - val_auc: 0.9871 - val_loss: 0.1372 - val_precision: 0.9755 - val_recall: 0.9425\n","Epoch 6/10\n","\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 186ms/step - accuracy: 0.9524 - auc: 0.9884 - loss: 0.1236 - precision: 0.9719 - recall: 0.9635 - val_accuracy: 0.9475 - val_auc: 0.9872 - val_loss: 0.1348 - val_precision: 0.9625 - val_recall: 0.9580\n","Epoch 7/10\n","\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 187ms/step - accuracy: 0.9421 - auc: 0.9860 - loss: 0.1354 - precision: 0.9642 - recall: 0.9573 - val_accuracy: 0.9491 - val_auc: 0.9874 - val_loss: 0.1322 - val_precision: 0.9619 - val_recall: 0.9612\n","Epoch 8/10\n","\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 187ms/step - accuracy: 0.9487 - auc: 0.9884 - loss: 0.1242 - precision: 0.9693 - recall: 0.9606 - val_accuracy: 0.9477 - val_auc: 0.9879 - val_loss: 0.1312 - val_precision: 0.9722 - val_recall: 0.9482\n","Epoch 9/10\n","\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 187ms/step - accuracy: 0.9528 - auc: 0.9891 - loss: 0.1200 - precision: 0.9734 - recall: 0.9623 - val_accuracy: 0.9515 - val_auc: 0.9880 - val_loss: 0.1276 - val_precision: 0.9646 - val_recall: 0.9619\n","Epoch 10/10\n","\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 188ms/step - accuracy: 0.9492 - auc: 0.9882 - loss: 0.1233 - precision: 0.9689 - recall: 0.9620 - val_accuracy: 0.9529 - val_auc: 0.9885 - val_loss: 0.1264 - val_precision: 0.9690 - val_recall: 0.9594\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Found 17906 images belonging to 2 classes.\n","Found 4286 images belonging to 2 classes.\n","Epoch 1/10\n","\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501ms/step - accuracy: 0.8413 - auc: 0.8929 - loss: 0.3541 - precision: 0.8782 - recall: 0.9130"]}],"source":["for BATCH_INDEX in range(4):\n","\n","  OPTIMIZER = tf.keras.optimizers.Adam()\n","\n","  LOSS_FUNCTION = tf.keras.losses.BinaryCrossentropy()\n","\n","  METRICS = [\n","      BinaryAccuracy(name=\"accuracy\"),\n","      Precision(name=\"precision\"),\n","      Recall(name=\"recall\"),\n","      AUC(name=\"auc\"),\n","  ]\n","\n","  BATCH_SIZES = [16, 32, 64, 128]\n","  BATCH_SIZE = BATCH_SIZES[BATCH_INDEX]\n","\n","  SUBVERSION = VERSION + f\".{BATCH_INDEX}\"\n","\n","  LOGS_PATH = os.path.abspath(f\"./logs\")\n","  if os.path.exists(LOGS_PATH):\n","    !rm -rf {LOGS_PATH}\n","  os.makedirs(LOGS_PATH, exist_ok=True)\n","\n","  MODELS_PATH = os.path.abspath(\"./models\")\n","  if os.path.exists(MODELS_PATH):\n","    !rm -rf {MODELS_PATH}\n","  os.makedirs(MODELS_PATH, exist_ok=True)\n","\n","\n","  train_datagen = ImageDataGenerator(\n","      preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n","  )\n","  train_images = train_datagen.flow_from_directory(\n","    directory=f\"{DATASET_DIR}/train\",\n","    target_size=IMAGE_SIZE,\n","    batch_size=BATCH_SIZE,\n","    class_mode=\"binary\",\n","    classes=['vacia', 'animal'],\n","    shuffle=True,\n","    seed=SEED,\n","  )\n","\n","  datagen = ImageDataGenerator(\n","      preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n","  )\n","  validation_images = datagen.flow_from_directory(\n","    directory=f\"{DATASET_DIR}/validation\",\n","    target_size=IMAGE_SIZE,\n","    batch_size=BATCH_SIZE,\n","    class_mode=\"binary\",\n","    classes=['vacia', 'animal'],\n","    shuffle=False,\n","    seed=SEED,\n","  )\n","\n","  pretrained_model = tf.keras.applications.EfficientNetB5(\n","      weights=\"imagenet\",\n","      include_top=False,\n","      input_shape=IMAGE_SHAPE,\n","  )\n","  pretrained_model.trainable = False\n","\n","  model = tf.keras.Sequential(\n","    [\n","        pretrained_model,\n","        tf.keras.layers.GlobalAveragePooling2D(),\n","        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n","    ],\n","    name=f\"{MODEL_NAME}_{SUBVERSION}\",\n","  )\n","\n","  model.compile(\n","      optimizer=OPTIMIZER,\n","      loss=LOSS_FUNCTION,\n","      metrics=METRICS,\n","  )\n","\n","  history = model.fit(\n","      train_images,\n","      epochs=EPOCHS,\n","      batch_size=BATCH_SIZE,\n","      validation_data=validation_images,\n","  )\n","\n","  dataframe = pd.DataFrame(history.history)\n","  history_path = os.path.join(LOGS_PATH, f\"history_{SUBVERSION}.csv\")\n","  dataframe.to_csv(history_path, sep=\";\", index=False)\n","\n","\n","  model.save(os.path.join(MODELS_PATH,f\"{MODEL_NAME}_{SUBVERSION}.weights.h5\"))\n","  model.save(os.path.join(MODELS_PATH,f\"{MODEL_NAME}_{SUBVERSION}.keras\"))\n","\n","  shutil.copytree(LOGS_PATH, os.path.join(BASE_PATH,f\"logs/{MODEL_NAME}/{VERSION}/{SUBVERSION}\"),dirs_exist_ok=True)\n","  shutil.copytree(MODELS_PATH, os.path.join(BASE_PATH,f\"models/{MODEL_NAME}/{VERSION}/{SUBVERSION}\"),dirs_exist_ok=True)"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"gpuType":"A100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}