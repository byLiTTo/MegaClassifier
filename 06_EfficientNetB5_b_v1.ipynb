{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"oQUZPTyG9M55","executionInfo":{"status":"ok","timestamp":1742679549476,"user_tz":-60,"elapsed":3849,"user":{"displayName":"Carlos García Silva","userId":"10388926223905764529"}}},"outputs":[],"source":["import os\n","\n","import numpy as np\n","import pandas as pd\n","import zipfile\n","import tensorflow as tf\n","import shutil\n","from sklearn.metrics import auc, confusion_matrix, roc_curve\n","from tensorflow.keras.callbacks import TensorBoard\n","from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall, AUC\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","BASE_PATH = os.path.abspath(\"./drive/MyDrive/MegaClassifier\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ua_x2H2FbfFz","executionInfo":{"status":"ok","timestamp":1742679574109,"user_tz":-60,"elapsed":24630,"user":{"displayName":"Carlos García Silva","userId":"10388926223905764529"}},"outputId":"ece5d7b8-bad0-46f3-8683-f0e521f8c3da"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["MODEL_NAME = \"MegaClassifier_b\"\n","VERSION = \"v1\""],"metadata":{"id":"YMZgeVIKTZiH","executionInfo":{"status":"ok","timestamp":1742679574125,"user_tz":-60,"elapsed":18,"user":{"displayName":"Carlos García Silva","userId":"10388926223905764529"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["DATASETS = {\n","    \"MegaClassifier_a\": \"onlyDetectionsForTrain\",\n","    \"MegaClassifier_b\": \"emptyOriginalAnimalDetection\",\n","    \"MegaClassifier_c\": \"emptyNonEmptyDataset\",\n","}"],"metadata":{"id":"ZB4MppQXbn2q","executionInfo":{"status":"ok","timestamp":1742679574130,"user_tz":-60,"elapsed":3,"user":{"displayName":"Carlos García Silva","userId":"10388926223905764529"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":26439,"status":"ok","timestamp":1742679600570,"user":{"displayName":"Carlos García Silva","userId":"10388926223905764529"},"user_tz":-60},"id":"1dW32L-3-Y3S"},"outputs":[],"source":["DATASET_PATH_ZIP = os.path.join(BASE_PATH, f\"data/processed/{DATASETS[MODEL_NAME]}.zip\")\n","with zipfile.ZipFile(DATASET_PATH_ZIP, 'r') as zip_ref:\n","      zip_ref.extractall(\"./data/processed\")\n","DATASET_DIR = os.path.abspath(f\"data/processed/{DATASETS[MODEL_NAME]}\")"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"_pThgKSR9M58","executionInfo":{"status":"ok","timestamp":1742679600587,"user_tz":-60,"elapsed":2,"user":{"displayName":"Carlos García Silva","userId":"10388926223905764529"}}},"outputs":[],"source":["EPOCHS = 10\n","\n","IMAGE_SIZE = (456, 456)\n","IMAGE_SHAPE = IMAGE_SIZE + (3,)\n","SEED = 42"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H5EH-u2Q9M5-","outputId":"32578410-1d53-4b78-c4e5-c4c96756289f","executionInfo":{"status":"ok","timestamp":1742685175521,"user_tz":-60,"elapsed":5574134,"user":{"displayName":"Carlos García Silva","userId":"10388926223905764529"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 19995 images belonging to 2 classes.\n","Found 4286 images belonging to 2 classes.\n","Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb5_notop.h5\n","\u001b[1m115263384/115263384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 169ms/step - accuracy: 0.8874 - auc: 0.9503 - loss: 0.2719 - precision: 0.9191 - recall: 0.9100 - val_accuracy: 0.9414 - val_auc: 0.9845 - val_loss: 0.1546 - val_precision: 0.9675 - val_recall: 0.9432\n","Epoch 2/10\n","\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 97ms/step - accuracy: 0.9444 - auc: 0.9863 - loss: 0.1461 - precision: 0.9640 - recall: 0.9509 - val_accuracy: 0.9452 - val_auc: 0.9864 - val_loss: 0.1408 - val_precision: 0.9690 - val_recall: 0.9475\n","Epoch 3/10\n","\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 101ms/step - accuracy: 0.9478 - auc: 0.9888 - loss: 0.1308 - precision: 0.9669 - recall: 0.9539 - val_accuracy: 0.9477 - val_auc: 0.9870 - val_loss: 0.1359 - val_precision: 0.9628 - val_recall: 0.9580\n","Epoch 4/10\n","\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 96ms/step - accuracy: 0.9467 - auc: 0.9893 - loss: 0.1273 - precision: 0.9646 - recall: 0.9542 - val_accuracy: 0.9487 - val_auc: 0.9878 - val_loss: 0.1316 - val_precision: 0.9648 - val_recall: 0.9573\n","Epoch 5/10\n","\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 94ms/step - accuracy: 0.9512 - auc: 0.9907 - loss: 0.1178 - precision: 0.9680 - recall: 0.9580 - val_accuracy: 0.9487 - val_auc: 0.9882 - val_loss: 0.1297 - val_precision: 0.9678 - val_recall: 0.9542\n","Epoch 6/10\n","\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 94ms/step - accuracy: 0.9523 - auc: 0.9914 - loss: 0.1142 - precision: 0.9686 - recall: 0.9585 - val_accuracy: 0.9515 - val_auc: 0.9884 - val_loss: 0.1279 - val_precision: 0.9633 - val_recall: 0.9633\n","Epoch 7/10\n","\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 95ms/step - accuracy: 0.9539 - auc: 0.9918 - loss: 0.1117 - precision: 0.9682 - recall: 0.9618 - val_accuracy: 0.9508 - val_auc: 0.9881 - val_loss: 0.1292 - val_precision: 0.9686 - val_recall: 0.9566\n","Epoch 8/10\n","\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 99ms/step - accuracy: 0.9540 - auc: 0.9915 - loss: 0.1117 - precision: 0.9692 - recall: 0.9607 - val_accuracy: 0.9484 - val_auc: 0.9883 - val_loss: 0.1268 - val_precision: 0.9602 - val_recall: 0.9619\n","Epoch 9/10\n","\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 99ms/step - accuracy: 0.9577 - auc: 0.9922 - loss: 0.1075 - precision: 0.9710 - recall: 0.9650 - val_accuracy: 0.9501 - val_auc: 0.9888 - val_loss: 0.1256 - val_precision: 0.9568 - val_recall: 0.9683\n","Epoch 10/10\n","\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 98ms/step - accuracy: 0.9584 - auc: 0.9924 - loss: 0.1067 - precision: 0.9739 - recall: 0.9626 - val_accuracy: 0.9517 - val_auc: 0.9892 - val_loss: 0.1250 - val_precision: 0.9747 - val_recall: 0.9517\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Found 19995 images belonging to 2 classes.\n","Found 4286 images belonging to 2 classes.\n","Epoch 1/10\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 351ms/step - accuracy: 0.8731 - auc: 0.9378 - loss: 0.3041 - precision: 0.9043 - recall: 0.9073 - val_accuracy: 0.9393 - val_auc: 0.9824 - val_loss: 0.1668 - val_precision: 0.9663 - val_recall: 0.9411\n","Epoch 2/10\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 197ms/step - accuracy: 0.9367 - auc: 0.9837 - loss: 0.1608 - precision: 0.9584 - recall: 0.9453 - val_accuracy: 0.9421 - val_auc: 0.9856 - val_loss: 0.1474 - val_precision: 0.9641 - val_recall: 0.9478\n","Epoch 3/10\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 196ms/step - accuracy: 0.9469 - auc: 0.9879 - loss: 0.1374 - precision: 0.9658 - recall: 0.9541 - val_accuracy: 0.9475 - val_auc: 0.9864 - val_loss: 0.1409 - val_precision: 0.9641 - val_recall: 0.9563\n","Epoch 4/10\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 198ms/step - accuracy: 0.9510 - auc: 0.9894 - loss: 0.1277 - precision: 0.9673 - recall: 0.9588 - val_accuracy: 0.9487 - val_auc: 0.9874 - val_loss: 0.1345 - val_precision: 0.9702 - val_recall: 0.9517\n","Epoch 5/10\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 200ms/step - accuracy: 0.9503 - auc: 0.9901 - loss: 0.1235 - precision: 0.9682 - recall: 0.9566 - val_accuracy: 0.9468 - val_auc: 0.9877 - val_loss: 0.1338 - val_precision: 0.9708 - val_recall: 0.9482\n","Epoch 6/10\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 197ms/step - accuracy: 0.9490 - auc: 0.9894 - loss: 0.1262 - precision: 0.9661 - recall: 0.9566 - val_accuracy: 0.9498 - val_auc: 0.9878 - val_loss: 0.1314 - val_precision: 0.9619 - val_recall: 0.9623\n","Epoch 7/10\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 197ms/step - accuracy: 0.9548 - auc: 0.9910 - loss: 0.1152 - precision: 0.9692 - recall: 0.9623 - val_accuracy: 0.9480 - val_auc: 0.9881 - val_loss: 0.1312 - val_precision: 0.9560 - val_recall: 0.9658\n","Epoch 8/10\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 198ms/step - accuracy: 0.9549 - auc: 0.9915 - loss: 0.1129 - precision: 0.9729 - recall: 0.9588 - val_accuracy: 0.9454 - val_auc: 0.9883 - val_loss: 0.1357 - val_precision: 0.9769 - val_recall: 0.9397\n","Epoch 9/10\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 198ms/step - accuracy: 0.9524 - auc: 0.9915 - loss: 0.1135 - precision: 0.9698 - recall: 0.9579 - val_accuracy: 0.9491 - val_auc: 0.9882 - val_loss: 0.1297 - val_precision: 0.9561 - val_recall: 0.9676\n","Epoch 10/10\n","\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 198ms/step - accuracy: 0.9574 - auc: 0.9923 - loss: 0.1075 - precision: 0.9712 - recall: 0.9646 - val_accuracy: 0.9487 - val_auc: 0.9888 - val_loss: 0.1270 - val_precision: 0.9722 - val_recall: 0.9496\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Found 19995 images belonging to 2 classes.\n","Found 4286 images belonging to 2 classes.\n","Epoch 1/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 643ms/step - accuracy: 0.8597 - auc: 0.9289 - loss: 0.3432 - precision: 0.9026 - recall: 0.8816 - val_accuracy: 0.9305 - val_auc: 0.9799 - val_loss: 0.1835 - val_precision: 0.9468 - val_recall: 0.9482\n","Epoch 2/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 385ms/step - accuracy: 0.9408 - auc: 0.9837 - loss: 0.1664 - precision: 0.9592 - recall: 0.9509 - val_accuracy: 0.9396 - val_auc: 0.9842 - val_loss: 0.1579 - val_precision: 0.9581 - val_recall: 0.9503\n","Epoch 3/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 387ms/step - accuracy: 0.9425 - auc: 0.9856 - loss: 0.1518 - precision: 0.9628 - recall: 0.9501 - val_accuracy: 0.9442 - val_auc: 0.9857 - val_loss: 0.1468 - val_precision: 0.9636 - val_recall: 0.9517\n","Epoch 4/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 388ms/step - accuracy: 0.9470 - auc: 0.9878 - loss: 0.1379 - precision: 0.9658 - recall: 0.9538 - val_accuracy: 0.9459 - val_auc: 0.9865 - val_loss: 0.1409 - val_precision: 0.9677 - val_recall: 0.9499\n","Epoch 5/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 386ms/step - accuracy: 0.9424 - auc: 0.9883 - loss: 0.1358 - precision: 0.9627 - recall: 0.9496 - val_accuracy: 0.9480 - val_auc: 0.9868 - val_loss: 0.1386 - val_precision: 0.9705 - val_recall: 0.9503\n","Epoch 6/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 387ms/step - accuracy: 0.9514 - auc: 0.9897 - loss: 0.1257 - precision: 0.9671 - recall: 0.9598 - val_accuracy: 0.9489 - val_auc: 0.9874 - val_loss: 0.1347 - val_precision: 0.9688 - val_recall: 0.9535\n","Epoch 7/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 386ms/step - accuracy: 0.9496 - auc: 0.9897 - loss: 0.1251 - precision: 0.9679 - recall: 0.9559 - val_accuracy: 0.9489 - val_auc: 0.9874 - val_loss: 0.1341 - val_precision: 0.9625 - val_recall: 0.9602\n","Epoch 8/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 386ms/step - accuracy: 0.9498 - auc: 0.9907 - loss: 0.1201 - precision: 0.9645 - recall: 0.9588 - val_accuracy: 0.9473 - val_auc: 0.9877 - val_loss: 0.1320 - val_precision: 0.9688 - val_recall: 0.9510\n","Epoch 9/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 387ms/step - accuracy: 0.9512 - auc: 0.9909 - loss: 0.1180 - precision: 0.9687 - recall: 0.9573 - val_accuracy: 0.9480 - val_auc: 0.9880 - val_loss: 0.1307 - val_precision: 0.9688 - val_recall: 0.9520\n","Epoch 10/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 387ms/step - accuracy: 0.9536 - auc: 0.9907 - loss: 0.1185 - precision: 0.9703 - recall: 0.9589 - val_accuracy: 0.9510 - val_auc: 0.9881 - val_loss: 0.1298 - val_precision: 0.9636 - val_recall: 0.9623\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Found 19995 images belonging to 2 classes.\n","Found 4286 images belonging to 2 classes.\n","Epoch 1/10\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 1s/step - accuracy: 0.8456 - auc: 0.9174 - loss: 0.3839 - precision: 0.8878 - recall: 0.8779 - val_accuracy: 0.9279 - val_auc: 0.9768 - val_loss: 0.2069 - val_precision: 0.9580 - val_recall: 0.9319\n","Epoch 2/10\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 758ms/step - accuracy: 0.9275 - auc: 0.9792 - loss: 0.1925 - precision: 0.9565 - recall: 0.9336 - val_accuracy: 0.9375 - val_auc: 0.9820 - val_loss: 0.1741 - val_precision: 0.9676 - val_recall: 0.9369\n","Epoch 3/10\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 763ms/step - accuracy: 0.9376 - auc: 0.9835 - loss: 0.1661 - precision: 0.9604 - recall: 0.9447 - val_accuracy: 0.9396 - val_auc: 0.9840 - val_loss: 0.1593 - val_precision: 0.9587 - val_recall: 0.9496\n","Epoch 4/10\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 762ms/step - accuracy: 0.9399 - auc: 0.9854 - loss: 0.1538 - precision: 0.9599 - recall: 0.9490 - val_accuracy: 0.9431 - val_auc: 0.9852 - val_loss: 0.1510 - val_precision: 0.9615 - val_recall: 0.9520\n","Epoch 5/10\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 763ms/step - accuracy: 0.9418 - auc: 0.9866 - loss: 0.1468 - precision: 0.9585 - recall: 0.9536 - val_accuracy: 0.9456 - val_auc: 0.9859 - val_loss: 0.1461 - val_precision: 0.9604 - val_recall: 0.9573\n","Epoch 6/10\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 782ms/step - accuracy: 0.9465 - auc: 0.9877 - loss: 0.1386 - precision: 0.9641 - recall: 0.9545 - val_accuracy: 0.9461 - val_auc: 0.9863 - val_loss: 0.1420 - val_precision: 0.9624 - val_recall: 0.9559\n","Epoch 7/10\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 786ms/step - accuracy: 0.9476 - auc: 0.9889 - loss: 0.1322 - precision: 0.9634 - recall: 0.9576 - val_accuracy: 0.9459 - val_auc: 0.9866 - val_loss: 0.1393 - val_precision: 0.9683 - val_recall: 0.9492\n","Epoch 8/10\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 781ms/step - accuracy: 0.9514 - auc: 0.9890 - loss: 0.1298 - precision: 0.9687 - recall: 0.9572 - val_accuracy: 0.9475 - val_auc: 0.9869 - val_loss: 0.1374 - val_precision: 0.9628 - val_recall: 0.9577\n","Epoch 9/10\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 768ms/step - accuracy: 0.9478 - auc: 0.9892 - loss: 0.1292 - precision: 0.9638 - recall: 0.9566 - val_accuracy: 0.9482 - val_auc: 0.9872 - val_loss: 0.1360 - val_precision: 0.9618 - val_recall: 0.9598\n","Epoch 10/10\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 771ms/step - accuracy: 0.9486 - auc: 0.9889 - loss: 0.1299 - precision: 0.9640 - recall: 0.9580 - val_accuracy: 0.9482 - val_auc: 0.9875 - val_loss: 0.1337 - val_precision: 0.9635 - val_recall: 0.9580\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}],"source":["for BATCH_INDEX in range(4):\n","\n","  OPTIMIZER = tf.keras.optimizers.Adam()\n","\n","  LOSS_FUNCTION = tf.keras.losses.BinaryCrossentropy()\n","\n","  METRICS = [\n","      BinaryAccuracy(name=\"accuracy\"),\n","      Precision(name=\"precision\"),\n","      Recall(name=\"recall\"),\n","      AUC(name=\"auc\"),\n","  ]\n","\n","  BATCH_SIZES = [16, 32, 64, 128]\n","  BATCH_SIZE = BATCH_SIZES[BATCH_INDEX]\n","\n","  SUBVERSION = VERSION + f\".{BATCH_INDEX}\"\n","\n","  LOGS_PATH = os.path.abspath(f\"./logs\")\n","  if os.path.exists(LOGS_PATH):\n","    !rm -rf {LOGS_PATH}\n","  os.makedirs(LOGS_PATH, exist_ok=True)\n","\n","  MODELS_PATH = os.path.abspath(\"./models\")\n","  if os.path.exists(MODELS_PATH):\n","    !rm -rf {MODELS_PATH}\n","  os.makedirs(MODELS_PATH, exist_ok=True)\n","\n","\n","  train_datagen = ImageDataGenerator(\n","      preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n","  )\n","  train_images = train_datagen.flow_from_directory(\n","    directory=f\"{DATASET_DIR}/train\",\n","    target_size=IMAGE_SIZE,\n","    batch_size=BATCH_SIZE,\n","    class_mode=\"binary\",\n","    classes=['vacia', 'animal'],\n","    shuffle=True,\n","    seed=SEED,\n","  )\n","\n","  datagen = ImageDataGenerator(\n","      preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n","  )\n","  validation_images = datagen.flow_from_directory(\n","    directory=f\"{DATASET_DIR}/validation\",\n","    target_size=IMAGE_SIZE,\n","    batch_size=BATCH_SIZE,\n","    class_mode=\"binary\",\n","    classes=['vacia', 'animal'],\n","    shuffle=False,\n","    seed=SEED,\n","  )\n","\n","  pretrained_model = tf.keras.applications.EfficientNetB5(\n","      weights=\"imagenet\",\n","      include_top=False,\n","      input_shape=IMAGE_SHAPE,\n","  )\n","  pretrained_model.trainable = False\n","\n","  model = tf.keras.Sequential(\n","    [\n","        pretrained_model,\n","        tf.keras.layers.GlobalAveragePooling2D(),\n","        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n","    ],\n","    name=f\"{MODEL_NAME}_{SUBVERSION}\",\n","  )\n","\n","  model.compile(\n","      optimizer=OPTIMIZER,\n","      loss=LOSS_FUNCTION,\n","      metrics=METRICS,\n","  )\n","\n","  history = model.fit(\n","      train_images,\n","      epochs=EPOCHS,\n","      batch_size=BATCH_SIZE,\n","      validation_data=validation_images,\n","  )\n","\n","  dataframe = pd.DataFrame(history.history)\n","  history_path = os.path.join(LOGS_PATH, f\"history_{SUBVERSION}.csv\")\n","  dataframe.to_csv(history_path, sep=\";\", index=False)\n","\n","\n","  model.save(os.path.join(MODELS_PATH,f\"{MODEL_NAME}_{SUBVERSION}.weights.h5\"))\n","  model.save(os.path.join(MODELS_PATH,f\"{MODEL_NAME}_{SUBVERSION}.keras\"))\n","\n","  shutil.copytree(LOGS_PATH, os.path.join(BASE_PATH,f\"logs/{MODEL_NAME}/{VERSION}/{SUBVERSION}\"),dirs_exist_ok=True)\n","  shutil.copytree(MODELS_PATH, os.path.join(BASE_PATH,f\"models/{MODEL_NAME}/{VERSION}/{SUBVERSION}\"),dirs_exist_ok=True)"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"gpuType":"A100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}