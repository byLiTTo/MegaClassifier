{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T09:06:02.391811Z",
     "start_time": "2025-02-24T08:56:32.361888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "MODEL_NAME = \"MegaClassifier_a\"\n",
    "VERSION_BASE = \"v5\"\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (224, 224)\n",
    "IMAGE_SHAPE = IMAGE_SIZE + (3,)\n",
    "SEED = 42\n",
    "\n",
    "DATASET_CSV = os.path.abspath(\"./data/processed/onlyDetectionsForTrain/onlyDetectionsForTrain.csv\")\n",
    "DATASET_PATH = os.path.dirname(DATASET_CSV)\n",
    "\n",
    "dataset = pd.read_csv(DATASET_CSV, sep=\";\")\n",
    "dataset['file_name'] = dataset['file_name'].apply(lambda x: os.path.join(DATASET_PATH, x))\n",
    "dataset['binary_label'] = dataset['binary_label'].astype(str)\n",
    "\n",
    "train_df = dataset[dataset['subset'] == 'train']\n",
    "validation_df = dataset[dataset['subset'] == 'validation']\n",
    "test_df = dataset[dataset['subset'] == 'test']\n",
    "\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\",\n",
    "                                     classes=np.unique(train_df['binary_label']),\n",
    "                                     y=train_df['binary_label'])\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "def focal_loss(alpha=0.25, gamma=1.0):\n",
    "    def loss(y_true, y_pred):\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "        pt = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        loss = -K.mean(alpha * K.pow(1. - pt, gamma) * K.log(pt))\n",
    "        return loss\n",
    "\n",
    "    return loss\n",
    "\n",
    "def train_and_evaluate():\n",
    "    print(f\"\\n🔹 Entrenando con Loss Weighting (pesos de clase) 🔹\")\n",
    "\n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input)\n",
    "    datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input)\n",
    "\n",
    "    train_images = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col=\"file_name\",\n",
    "        y_col=\"binary_label\",\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=True,\n",
    "        seed=SEED,\n",
    "    )\n",
    "    validation_images = datagen.flow_from_dataframe(\n",
    "        dataframe=validation_df,\n",
    "        x_col=\"file_name\",\n",
    "        y_col=\"binary_label\",\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=True,\n",
    "        seed=SEED,\n",
    "    )\n",
    "    test_images = datagen.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        x_col=\"file_name\",\n",
    "        y_col=\"binary_label\",\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=\"binary\",\n",
    "    )\n",
    "\n",
    "    mobilenet_v2 = tf.keras.applications.MobileNetV2(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        input_shape=IMAGE_SHAPE,\n",
    "    )\n",
    "    mobilenet_v2.trainable = False\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        mobilenet_v2,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ], name=f\"{MODEL_NAME}_{VERSION_BASE}\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "        loss=focal_loss(alpha=0.25, gamma=1.0),\n",
    "        metrics=[\"accuracy\", Precision(name=\"precision\"), Recall(name=\"recall\"), AUC(name=\"auc\")],\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        train_images,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=validation_images,\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=[\n",
    "            TensorBoard(log_dir=f\"./logs/{MODEL_NAME}/{VERSION_BASE}\"),\n",
    "        ]\n",
    "    )\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    results = model.evaluate(test_images)\n",
    "\n",
    "    # ✅ Guardar métricas y resultados\n",
    "    history_df = pd.DataFrame(history.history)\n",
    "    os.makedirs(f\"./logs/{MODEL_NAME}/{VERSION_BASE}\", exist_ok=True)\n",
    "    history_df.to_csv(f\"./logs/{MODEL_NAME}/{VERSION_BASE}/history_{VERSION_BASE}.0.csv\", index=False)\n",
    "\n",
    "    metric_names = history.model.metrics_names\n",
    "    evaluation_results = {(\"test_\" + name): value for name, value in zip(metric_names, results)}\n",
    "    evaluation_results[\"training_time\"] = training_time\n",
    "\n",
    "    results_df = pd.DataFrame([evaluation_results])\n",
    "    results_df.to_csv(f\"./logs/{MODEL_NAME}/{VERSION_BASE}/results_{VERSION_BASE}.0.csv\", index=False)\n",
    "\n",
    "    print(f\"\\n📉 Loss: {results[0]:.4f}\")\n",
    "    print(f\"🎯 Accuracy: {results[1]:.4%}\")\n",
    "    print(f\"✅ Precision: {results[2]:.4%}\")\n",
    "    print(f\"🔄 Recall: {results[3]:.4%}\")\n",
    "    print(f\"📊 AUC: {results[4]:.4f}\")\n",
    "    print(f\"⏳ Tiempo de entrenamiento: {training_time:.2f} segundos\")\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "results_df = train_and_evaluate()\n",
    "\n",
    "print(\"\\n✅ ¡Entrenamiento con Loss Weighting completado!\")"
   ],
   "id": "7d11e162eeed628f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Entrenando con Loss Weighting (pesos de clase) 🔹\n",
      "Found 17054 validated image filenames belonging to 2 classes.\n",
      "Found 4286 validated image filenames belonging to 2 classes.\n",
      "Found 4286 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-24 09:56:35.851063: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
      "2025-02-24 09:56:35.851090: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-02-24 09:56:35.851095: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-02-24 09:56:35.851127: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-02-24 09:56:35.851286: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-24 09:56:37.456938: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533/533 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.8762 - precision: 0.9059 - recall: 0.9377 - auc: 0.9286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-24 09:57:22.506885: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533/533 [==============================] - 57s 104ms/step - loss: 0.0355 - accuracy: 0.8762 - precision: 0.9059 - recall: 0.9377 - auc: 0.9286 - val_loss: 0.0262 - val_accuracy: 0.9162 - val_precision: 0.9548 - val_recall: 0.9168 - val_auc: 0.9732\n",
      "Epoch 2/10\n",
      "533/533 [==============================] - 55s 102ms/step - loss: 0.0260 - accuracy: 0.9136 - precision: 0.9399 - recall: 0.9492 - auc: 0.9639 - val_loss: 0.0245 - val_accuracy: 0.9288 - val_precision: 0.9341 - val_recall: 0.9602 - val_auc: 0.9762\n",
      "Epoch 3/10\n",
      "533/533 [==============================] - 56s 105ms/step - loss: 0.0238 - accuracy: 0.9225 - precision: 0.9470 - recall: 0.9534 - auc: 0.9700 - val_loss: 0.0219 - val_accuracy: 0.9340 - val_precision: 0.9597 - val_recall: 0.9397 - val_auc: 0.9802\n",
      "Epoch 4/10\n",
      "533/533 [==============================] - 55s 103ms/step - loss: 0.0224 - accuracy: 0.9278 - precision: 0.9519 - recall: 0.9551 - auc: 0.9735 - val_loss: 0.0206 - val_accuracy: 0.9382 - val_precision: 0.9534 - val_recall: 0.9531 - val_auc: 0.9821\n",
      "Epoch 5/10\n",
      "533/533 [==============================] - 55s 103ms/step - loss: 0.0216 - accuracy: 0.9315 - precision: 0.9535 - recall: 0.9584 - auc: 0.9755 - val_loss: 0.0205 - val_accuracy: 0.9386 - val_precision: 0.9516 - val_recall: 0.9559 - val_auc: 0.9822\n",
      "Epoch 6/10\n",
      "533/533 [==============================] - 55s 103ms/step - loss: 0.0209 - accuracy: 0.9332 - precision: 0.9553 - recall: 0.9586 - auc: 0.9769 - val_loss: 0.0209 - val_accuracy: 0.9365 - val_precision: 0.9638 - val_recall: 0.9394 - val_auc: 0.9816\n",
      "Epoch 7/10\n",
      "533/533 [==============================] - 55s 104ms/step - loss: 0.0204 - accuracy: 0.9349 - precision: 0.9565 - recall: 0.9597 - auc: 0.9783 - val_loss: 0.0201 - val_accuracy: 0.9410 - val_precision: 0.9470 - val_recall: 0.9647 - val_auc: 0.9831\n",
      "Epoch 8/10\n",
      "533/533 [==============================] - 55s 104ms/step - loss: 0.0199 - accuracy: 0.9364 - precision: 0.9576 - recall: 0.9604 - auc: 0.9792 - val_loss: 0.0199 - val_accuracy: 0.9414 - val_precision: 0.9530 - val_recall: 0.9587 - val_auc: 0.9835\n",
      "Epoch 9/10\n",
      "533/533 [==============================] - 55s 103ms/step - loss: 0.0197 - accuracy: 0.9384 - precision: 0.9590 - recall: 0.9617 - auc: 0.9797 - val_loss: 0.0198 - val_accuracy: 0.9426 - val_precision: 0.9609 - val_recall: 0.9520 - val_auc: 0.9829\n",
      "Epoch 10/10\n",
      "533/533 [==============================] - 57s 107ms/step - loss: 0.0192 - accuracy: 0.9384 - precision: 0.9587 - recall: 0.9620 - auc: 0.9806 - val_loss: 0.0197 - val_accuracy: 0.9435 - val_precision: 0.9635 - val_recall: 0.9506 - val_auc: 0.9836\n",
      "134/134 [==============================] - 11s 83ms/step - loss: 0.0177 - accuracy: 0.9438 - precision: 0.9593 - recall: 0.9556 - auc: 0.9868\n",
      "\n",
      "📉 Loss: 0.0177\n",
      "🎯 Accuracy: 94.3770%\n",
      "✅ Precision: 95.9292%\n",
      "🔄 Recall: 95.5571%\n",
      "📊 AUC: 0.9868\n",
      "⏳ Tiempo de entrenamiento: 554.42 segundos\n",
      "\n",
      "✅ ¡Entrenamiento con Loss Weighting completado!\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TFG] *",
   "language": "python",
   "name": "conda-env-TFG-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
