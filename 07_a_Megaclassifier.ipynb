{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tqdm\n",
    "from keras.callbacks import TensorBoard\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import src.data.Dataset as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHONPATH: :/Users/carlos/WORKSPACE/MegaClassifier/data/external/ai4eutils:/Users/carlos/WORKSPACE/MegaClassifier/data/external/CameraTraps:/Users/carlos/WORKSPACE/MegaClassifier/data/external/yolov5\n"
     ]
    }
   ],
   "source": [
    "required_paths = [\"/ai4eutils\", \"/CameraTraps\", \"/yolov5\"]\n",
    "python_path = os.environ.get(\"PYTHONPATH\", \"\")\n",
    "root_path = os.getcwd()\n",
    "\n",
    "for path in required_paths:\n",
    "    if not any(p.endswith(path) for p in python_path.split(\":\")):\n",
    "        python_path += f\":{root_path}/data/external{path}\"\n",
    "\n",
    "os.environ[\"PYTHONPATH\"] = python_path\n",
    "\n",
    "!echo \"PYTHONPATH: $PYTHONPATH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"v1.0\"\n",
    "\n",
    "img_weight = 224\n",
    "img_height = 224\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "seed = 42\n",
    "\n",
    "epochs = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MegaClassifier_v1.0\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 1280)              2257984   \n",
      "                                                                 \n",
      " Output_Layer (Dense)        (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 1,281\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "datagen_train = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# mobilenetV2 = MobileNetV2(\n",
    "#     include_top=False, input_shape=(img_weight, img_height, 3), weights=\"imagenet\"\n",
    "# )\n",
    "\n",
    "url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "mobilenetV2 = hub.KerasLayer(url, input_shape=(img_weight, img_height, 3))\n",
    "\n",
    "mobilenetV2.trainable = False\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        mobilenetV2,\n",
    "        Dense(1, activation=\"sigmoid\", name=\"Output_Layer\"),\n",
    "    ],\n",
    "    name=f\"MegaClassifier_{version}\",\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    f\"./models/MegaClassifier_//best_MegaClassifier__{version}.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    mode=\"min\",\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=4,\n",
    "    mode=\"min\",\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "tensorBoard = TensorBoard(log_dir=f\"./logs/MegaClassifier_/{version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET_PATH:   /Users/carlos/WORKSPACE/MegaClassifier/dataset/datasetFiltered\n",
      "TRAIN_CSV:      /Users/carlos/WORKSPACE/MegaClassifier/data/processed/train/29618Train.csv\n",
      "VALIDATION_CSV: /Users/carlos/WORKSPACE/MegaClassifier/data/processed/validation/29618Validation.csv\n",
      "TEST_CSV:       /Users/carlos/WORKSPACE/MegaClassifier/data/processed/test/29618Test.csv\n",
      "FILTERED_CSV:   /Users/carlos/WORKSPACE/MegaClassifier/data/interim/29618Images_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = os.path.abspath(\"./dataset/datasetFiltered\")\n",
    "\n",
    "TRAIN_CSV = os.path.abspath(\"./data/processed/train/29618Train.csv\")\n",
    "VALIDATION_CSV = os.path.abspath(\"./data/processed/validation/29618Validation.csv\")\n",
    "TEST_CSV = os.path.abspath(\"./data/processed/test/29618Test.csv\")\n",
    "FILTERED_CSV = os.path.abspath(\"./data/interim/29618Images_filtered.csv\")\n",
    "\n",
    "print(f\"DATASET_PATH:   {DATASET_PATH}\")\n",
    "print(f\"TRAIN_CSV:      {TRAIN_CSV}\")\n",
    "print(f\"VALIDATION_CSV: {VALIDATION_CSV}\")\n",
    "print(f\"TEST_CSV:       {TEST_CSV}\")\n",
    "print(f\"FILTERED_CSV:   {FILTERED_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file /Users/carlos/WORKSPACE/MegaClassifier/data/processed/train/29618Train.csv has been successfully opened.\n",
      "The file /Users/carlos/WORKSPACE/MegaClassifier/data/processed/validation/29618Validation.csv has been successfully opened.\n",
      "The file /Users/carlos/WORKSPACE/MegaClassifier/data/processed/test/29618Test.csv has been successfully opened.\n",
      "The file /Users/carlos/WORKSPACE/MegaClassifier/data/interim/29618Images_filtered.csv has been successfully opened.\n"
     ]
    }
   ],
   "source": [
    "train_csv = dt.load_from_csv(TRAIN_CSV)\n",
    "vali_csv = dt.load_from_csv(VALIDATION_CSV)\n",
    "test_csv = dt.load_from_csv(TEST_CSV)\n",
    "filtered_csv = dt.load_from_csv(FILTERED_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 28560\n"
     ]
    }
   ],
   "source": [
    "ruta = \"/Users/carlos/WORKSPACE/MegaClassifier/dataset/emptyNonEmptyDataset\"\n",
    "ruta = \"/Users/carlos/WORKSPACE/MegaClassifier/dataset/datasetFiltered\"\n",
    "\n",
    "image_count = sum([len(files) for r, d, files in os.walk(ruta)])\n",
    "print(f\"Total number of images: {image_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique images: 28560\n"
     ]
    }
   ],
   "source": [
    "unique_images_count = filtered_csv.drop_duplicates(subset=\"file_name\").shape[0]\n",
    "print(f\"Number of unique images: {unique_images_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file /Users/carlos/WORKSPACE/MegaClassifier/data/interim/29618Images_filtered.csv has been successfully opened.\n",
      "/Users/carlos/WORKSPACE/MegaClassifier/dataset/datasetFiltered/vacia/empty_caltechcameratraps/59ac6d47-23d2-11e8-a6a3-ec086b02610b.jpg\n",
      "/Users/carlos/WORKSPACE/MegaClassifier/dataset/datasetFiltered/vacia/noanimal_zoo_1_4/34_20210115_2825_.jpg\n",
      "/Users/carlos/WORKSPACE/MegaClassifier/dataset/datasetFiltered/leporido/rabbit_caltechcameratrap_me/58b8238c-23d2-11e8-a6a3-ec086b02610b.jpg\n",
      "/Users/carlos/WORKSPACE/MegaClassifier/dataset/datasetFiltered/gineta/gineta_pnm_2012_isaac/d14639file0027.jpg\n",
      "/Users/carlos/WORKSPACE/MegaClassifier/dataset/datasetFiltered/caballo/horse_zoo_1_4/15_20210117_13096_.jpg\n",
      "/Users/carlos/WORKSPACE/MegaClassifier/dataset/datasetFiltered/caballo/caballos_javier_jc/2_20201117_3542_.jpg\n",
      "/Users/carlos/WORKSPACE/MegaClassifier/dataset/datasetFiltered/zorro/zorro_pnc_2013-o_red_isaac/b19370imag0058.jpg\n",
      "/Users/carlos/WORKSPACE/MegaClassifier/dataset/datasetFiltered/humanovehiculo/humanorvehicle_zoo_1_4/5_20210115_5_.jpg\n",
      "/Users/carlos/WORKSPACE/MegaClassifier/dataset/datasetFiltered/vacia/noanimal_zoo_1_4/7_20210115_960_.jpg\n",
      "/Users/carlos/WORKSPACE/MegaClassifier/dataset/datasetFiltered/jabali/wildboar_zoo_1_4/42_20210114_187_.jpg\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = os.path.abspath(\"./dataset/datasetFiltered\")\n",
    "FILTERED_CSV = os.path.abspath(\"./data/interim/29618Images_filtered.csv\")\n",
    "filtered_csv = dt.load_from_csv(FILTERED_CSV)\n",
    "\n",
    "filtered_csv[\"file_name\"] = filtered_csv[\"file_name\"].apply(\n",
    "    lambda x: os.path.join(DATASET_PATH, x)\n",
    ")\n",
    "\n",
    "# Buscar duplicados basados en la columna 'file_name'\n",
    "duplicated_rows = filtered_csv[filtered_csv.duplicated(subset=\"file_name\", keep=False)]\n",
    "\n",
    "# Comprobar si los duplicated_rows tienen el mismo valor de label\n",
    "duplicated_rows_same_label = (\n",
    "    duplicated_rows.groupby(\"file_name\")[\"label\"].nunique().eq(1)\n",
    ")\n",
    "\n",
    "# Mostrar algunas rutas de las imágenes duplicadas\n",
    "for file_name in duplicated_rows[\"file_name\"].unique()[:10]:\n",
    "    print(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILE_PATH = os.path.abspath(\n",
    "    \"./resources/json/md_v5a/29618_images_0_003_threshold.json\"\n",
    ")\n",
    "\n",
    "with open(OUTPUT_FILE_PATH, \"r\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29618/29618 [00:32<00:00, 899.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vacia/vacia_paco_carro_jc/img_0412.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vacia/vacia_paco_carro_jc/img_0412.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meloncillo/egyptianmongoose_zoo_1_4/36_2021011...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meloncillo/egyptianmongoose_zoo_1_4/36_2021011...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vacia/noanimal_zoo_5_6_7_9/49_20210418_4768_.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4252</th>\n",
       "      <td>ave/ave_ave_wellingtoncameratraps_ss/011016170...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4253</th>\n",
       "      <td>ave/ave_soraya_padilla_alumno_1_th/stc_0223_fr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4254</th>\n",
       "      <td>ave/ave_soraya_padilla_alumno_1_th/stc_0223_fr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4255</th>\n",
       "      <td>vacia/noanimal_zoo_1_4/6_20201812_11645_.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4256</th>\n",
       "      <td>vacia/noanimal_zoo_1_4/6_20201812_11645_.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4257 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              file_name label\n",
       "0                vacia/vacia_paco_carro_jc/img_0412.jpg     0\n",
       "1                vacia/vacia_paco_carro_jc/img_0412.jpg     0\n",
       "2     meloncillo/egyptianmongoose_zoo_1_4/36_2021011...     1\n",
       "3     meloncillo/egyptianmongoose_zoo_1_4/36_2021011...     1\n",
       "4      vacia/noanimal_zoo_5_6_7_9/49_20210418_4768_.jpg     0\n",
       "...                                                 ...   ...\n",
       "4252  ave/ave_ave_wellingtoncameratraps_ss/011016170...     1\n",
       "4253  ave/ave_soraya_padilla_alumno_1_th/stc_0223_fr...     1\n",
       "4254  ave/ave_soraya_padilla_alumno_1_th/stc_0223_fr...     1\n",
       "4255       vacia/noanimal_zoo_1_4/6_20201812_11645_.jpg     0\n",
       "4256       vacia/noanimal_zoo_1_4/6_20201812_11645_.jpg     0\n",
       "\n",
       "[4257 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_columns = [\n",
    "    \"file_name\",\n",
    "    \"label\",\n",
    "    \"detector_label\",\n",
    "]\n",
    "dataset = pd.DataFrame(columns=predict_columns)\n",
    "\n",
    "duplicate_row = [\"file_name\", \"label\"]\n",
    "duplicates = pd.DataFrame(columns=duplicate_row)\n",
    "\n",
    "for image in tqdm.tqdm(data[\"images\"]):\n",
    "    # image_file = DATASET_PATH + \"/\"+ image[\"file\"]\n",
    "    image_file = image[\"file\"]\n",
    "    indexes = filtered_csv[filtered_csv[\"file_name\"] == image_file]\n",
    "\n",
    "    if len(indexes) == 1:\n",
    "        label = int(indexes[\"label\"].iloc[0])\n",
    "        detector_label = 0 if image[\"max_detection_conf\"] == 0.0 else 1\n",
    "\n",
    "        new_row = {\n",
    "            \"file_name\": image_file,\n",
    "            \"label\": label,\n",
    "            \"detector_label\": detector_label,\n",
    "        }\n",
    "        dataset = pd.concat([dataset, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    elif len(indexes) > 1:\n",
    "        for idx in indexes.index:\n",
    "            duplicate_row = {\n",
    "                \"file_name\": indexes.at[idx, \"file_name\"],\n",
    "                \"label\": indexes.at[idx, \"label\"],\n",
    "            }\n",
    "            duplicates = pd.concat(\n",
    "                [duplicates, pd.DataFrame([duplicate_row])], ignore_index=True\n",
    "            )\n",
    "\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar el dataset para obtener las filas que cumplen con las condiciones\n",
    "filtered_images = dataset[(dataset[\"detector_label\"] == 1) & (dataset[\"label\"] == 0)]\n",
    "filtered_images[\"file_name\"]\n",
    "\n",
    "# for item in data[\"images\"]:\n",
    "#     if item[\"file\"] in filtered_images[\"file_name\"].values:\n",
    "#         if item[\"detections\"] == []:\n",
    "#             print(item)\n",
    "#             print(os.path.join(DATASET_PATH, item[\"file\"]))\n",
    "#             print(\n",
    "#                 os.path.join(os.path.abspath(\"./dataset/datasetFiltered\"), item[\"file\"])\n",
    "#             )\n",
    "#             print(dataset[dataset[\"file_name\"] == item[\"file\"]])\n",
    "#             print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of openable images: 27527\n",
      "Number of not openable images: 0\n",
      "Not openable files: []\n"
     ]
    }
   ],
   "source": [
    "# Ruta base\n",
    "base_path = DATASET_PATH\n",
    "\n",
    "# Contadores para las imágenes que se pueden y no se pueden abrir\n",
    "count_openable = 0\n",
    "count_not_openable = 0\n",
    "\n",
    "# Lista para almacenar las rutas de las imágenes que no se pueden abrir\n",
    "not_openable_files = []\n",
    "\n",
    "# Iterar sobre las rutas de las imágenes en el dataset\n",
    "# for image in data[\"images\"]:\n",
    "# file_path = image[\"file\"]\n",
    "for file_path in dataset[\"file_name\"]:\n",
    "    absolute_path = base_path + \"/\" + file_path\n",
    "    try:\n",
    "        # Intentar abrir la imagen\n",
    "        img = Image.open(absolute_path)\n",
    "        img.verify()  # Verificar que la imagen se puede abrir\n",
    "        count_openable += 1\n",
    "    except (IOError, SyntaxError) as e:\n",
    "        # Si hay un error, incrementar el contador de imágenes no abiertas\n",
    "        count_not_openable += 1\n",
    "        not_openable_files.append(absolute_path)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f\"Number of openable images: {count_openable}\")\n",
    "print(f\"Number of not openable images: {count_not_openable}\")\n",
    "print(f\"Not openable files: {not_openable_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"file_name\", \"label\"]\n",
    "\n",
    "count = 0\n",
    "data = []\n",
    "for _, row in train_csv.iterrows():\n",
    "    if (\n",
    "        dataset[dataset[\"file_name\"] == row[\"file_name\"]][\"detector_label\"].values.size\n",
    "        == 0\n",
    "    ):\n",
    "        print(os.path.join(os.path.abspath(\"./resources/\"), row[\"file_name\"]))\n",
    "        count += 1\n",
    "print(count)\n",
    "#     if dataset[dataset['file_name'] == row[\"file_name\"]]['detector_label'].values[0] == 1:\n",
    "#         file_name = os.path.join(DATASET_PATH, row[\"file_name\"])\n",
    "#         label = row[\"label\"]\n",
    "#         data.append([file_name, label])\n",
    "#     else:\n",
    "#         continue\n",
    "# train_dataset = pd.DataFrame(data, columns=columns)\n",
    "# train_dataset[\"label\"] = train_dataset[\"label\"].astype(str)\n",
    "# train_dataset\n",
    "\n",
    "# data = []\n",
    "# for _, row in tqdm.tqdm(vali_csv.iterrows()):\n",
    "#     if dataset[dataset['file_name'] == row[\"file_name\"]]['detector_label'].values[0] == 1:\n",
    "#         file_name = os.path.join(DATASET_PATH, row[\"file_name\"])\n",
    "#         label = row[\"label\"]\n",
    "#         data.append([file_name, label])\n",
    "#     else:\n",
    "#         continue\n",
    "# vali_dataset = pd.DataFrame(data, columns=columns)\n",
    "# vali_dataset[\"label\"] = vali_dataset[\"label\"].astype(str)\n",
    "\n",
    "# data = []\n",
    "# for _, row in tqdm.tqdm(test_csv.iterrows()):\n",
    "#     if dataset[dataset['file_name'] == row[\"file_name\"]]['detector_label'].values[0] == 1:\n",
    "#         file_name = os.path.join(DATASET_PATH, row[\"file_name\"])\n",
    "#         label = row[\"label\"]\n",
    "#         data.append([file_name, label])\n",
    "#     else:\n",
    "#         continue\n",
    "# test_dataset = pd.DataFrame(data, columns=columns)\n",
    "# test_dataset[\"label\"] = test_dataset[\"label\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_weight = 224\n",
    "# img_height = 224\n",
    "img_weight = 1000\n",
    "img_height = 1000\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "seed = 42\n",
    "\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_train = ImageDataGenerator(\n",
    "    rescale=1.0 / 255, horizontal_flip=True, brightness_range=[0.8, 1.2]\n",
    ")\n",
    "datagen_val_test = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "train_generator = datagen_train.flow_from_dataframe(\n",
    "    dataframe=train_dataset,\n",
    "    x_col=\"file_name\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(img_weight, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=True,\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "val_generator = datagen_val_test.flow_from_dataframe(\n",
    "    dataframe=vali_dataset,\n",
    "    x_col=\"file_name\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(img_weight, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=True,\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "test_generator = datagen_val_test.flow_from_dataframe(\n",
    "    dataframe=test_dataset,\n",
    "    x_col=\"file_name\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(img_weight, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar el dataset para obtener las filas que cumplen con las condiciones\n",
    "filtered_images = dataset[(dataset[\"detector_label\"] == 1) & (dataset[\"label\"] == 0)]\n",
    "\n",
    "# Mostrar las rutas de las imágenes\n",
    "image_paths = filtered_images[\"file_name\"].tolist()\n",
    "for image_path in image_paths:\n",
    "    detections = next(\n",
    "        (img[\"detections\"] for img in data[\"images\"] if img[\"file\"] == image_path), None\n",
    "    )\n",
    "    print(f\"Image: {image_path}, Detections: {detections}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetV2 = MobileNetV2(\n",
    "    include_top=False,\n",
    "    input_shape=(img_weight, img_height, 3),\n",
    "    weights=\"imagenet\",\n",
    ")\n",
    "\n",
    "mobilenetV2.trainable = False\n",
    "\n",
    "model = Sequential(\n",
    "    [mobilenetV2, GlobalAveragePooling2D(), Dense(1, activation=\"sigmoid\")]\n",
    ")\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    \"./models/MegaClassifier/md_v5a_MobileNetV2_V1.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    mode=\"min\",\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=4,\n",
    "    mode=\"min\",\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "tensorBoard = TensorBoard(log_dir=\"./logs/Megaclassifier/MobileNetV2/version_1\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=2000 // batch_size,\n",
    "    callbacks=[checkpoint, early_stop, tensorBoard],\n",
    "    # verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_training_history(history):\n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label=\"Accuracy\")\n",
    "    plt.plot(epochs_range, val_acc, label=\"Validation Accuracy\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label=\"Loss\")\n",
    "    plt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "megaclassifier_v1 = load_model(\"./models/MegaClassifier/md_v5a_MobileNetV2_V1.h5\")\n",
    "evaluate = megaclassifier_v1.evaluate(test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_generator.classes\n",
    "\n",
    "predict = megaclassifier_v1.predict(test_generator)\n",
    "predict_flatten = predict.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "random_flatten = np.zeros_like(test_labels)\n",
    "\n",
    "random_auc = roc_auc_score(test_labels, random_flatten)\n",
    "megaclassifier_auc = roc_auc_score(test_labels, predict_flatten)\n",
    "\n",
    "print(\"Random Classifier: ROC AUC=%.1f\" % (random_auc))\n",
    "print(\"Megaclassifier V1: ROC AUC=%.4f\" % (megaclassifier_auc))\n",
    "\n",
    "random_false_positive_rate, random_true_positive_rate, _ = roc_curve(\n",
    "    test_labels, random_flatten\n",
    ")\n",
    "megaclassifier_false_positive_rate, megaclassifier_true_positive_rate, _ = roc_curve(\n",
    "    test_labels, predict_flatten\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    random_false_positive_rate,\n",
    "    random_true_positive_rate,\n",
    "    linestyle=\"--\",\n",
    "    label=\"Aleatorio: ROC AUC=%.1f\" % (random_auc),\n",
    ")\n",
    "plt.plot(\n",
    "    megaclassifier_false_positive_rate,\n",
    "    megaclassifier_true_positive_rate,\n",
    "    label=\"Megaclassifier V1: ROC AUC=%.4f\" % (megaclassifier_auc),\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Tasa de Falsos Positivos\")\n",
    "plt.ylabel(\"Tasa de Verdaderos Positivos\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = evaluate\n",
    "\n",
    "df_results = pd.DataFrame(\n",
    "    {\n",
    "        \"False Positive Rate\": megaclassifier_false_positive_rate,\n",
    "        \"True Positive Rate\": megaclassifier_true_positive_rate,\n",
    "        \"AUC\": [megaclassifier_auc] * len(megaclassifier_false_positive_rate),\n",
    "        \"Loss\": [loss] * len(megaclassifier_false_positive_rate),\n",
    "        \"Accuracy\": [accuracy] * len(megaclassifier_false_positive_rate),\n",
    "    }\n",
    ")\n",
    "\n",
    "os.makedirs(\"./logs/Megaclassifier/MobileNetV2/version_1/test\", exist_ok=True)\n",
    "df_results.to_csv(\n",
    "    \"./logs/Megaclassifier/MobileNetV2/version_1/test/megaclassifier_v1_results.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cameratraps-detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
