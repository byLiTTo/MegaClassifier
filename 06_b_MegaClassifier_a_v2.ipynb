{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import src.graphics as graphics\n",
    "import src.model as model"
   ],
   "id": "3a510b979ca2e35a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "MODEL_NAME = \"MegaClassifier_a\"\n",
    "VERSION = \"v2\"\n",
    "SUBVERSION = 0\n",
    "\n",
    "DATASET_CSV = os.path.abspath(\"./data/processed/onlyDetectionsForTrain/onlyDetectionsForTrain.csv\")\n",
    "DATASET_PATH = os.path.dirname(DATASET_CSV)"
   ],
   "id": "5d78f307f4361808",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = pd.read_csv(DATASET_CSV, sep=\";\")\n",
    "dataset['file_name'] = dataset['file_name'].apply(lambda x: os.path.join(DATASET_PATH, x))\n",
    "dataset['binary_label'] = dataset['binary_label'].astype(str)\n",
    "\n",
    "train_dataset = dataset[dataset['subset'] == \"train\"]\n",
    "validation_dataset = dataset[dataset['subset'] == \"validation\"]\n",
    "test_dataset = dataset[dataset['subset'] == \"test\"]"
   ],
   "id": "fdd385a1b5f4c70b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "LOSS_FUNCTIONS = {\n",
    "    \"BinaryCrossentropy\": tf.keras.losses.BinaryCrossentropy(),\n",
    "    \"BinaryFocalCrossentropy\": tf.keras.losses.BinaryFocalCrossentropy(alpha=0.25, gamma=2.0),\n",
    "    \"WeightedBinaryCrossentropy\": tf.keras.losses.BinaryCrossentropy(),\n",
    "    \"SigmoidFocalCrossEntropy\": tfa.losses.SigmoidFocalCrossEntropy(alpha=0.25, gamma=2.0),\n",
    "    \"FocalLoss\": model.FocalLoss(alpha=0.25, gamma=2.0),\n",
    "}\n",
    "\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\",\n",
    "                                     classes=np.unique(train_dataset['binary_label']),\n",
    "                                     y=train_dataset['binary_label'])\n",
    "WEIGHTS = {i: class_weights[i] for i in range(len(class_weights))}"
   ],
   "id": "e772640c3899418e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_results = []\n",
    "for LOSS_NAME, LOSS_FUNCTION in LOSS_FUNCTIONS.items():\n",
    "    train_generator, other_generator = model.image_data_generator(version=VERSION)\n",
    "\n",
    "    train_images, validation_images, test_images = model.flow_from_dataframe(\n",
    "        datasets=[train_dataset, validation_dataset, test_dataset],\n",
    "        generators=[train_generator, other_generator],\n",
    "        batch_size=BATCH_SIZE,\n",
    "    )\n",
    "\n",
    "    mobilenet_v2 = model.load_pretrained(version=VERSION)\n",
    "\n",
    "    mega_classifier_a = model.compile_model(\n",
    "        version=VERSION,\n",
    "        pretrained_model=mobilenet_v2,\n",
    "        loss_function=LOSS_FUNCTION,\n",
    "        weights=WEIGHTS if LOSS_NAME == \"WeightedBinaryCrossentropy\" else None,\n",
    "        name=f\"{MODEL_NAME}_{VERSION}_{SUBVERSION}\")\n",
    "\n",
    "    callbacks = model.callbacks(\n",
    "        version=VERSION,\n",
    "        logs_path=f\"./logs/{MODEL_NAME}/{VERSION}/{VERSION}.{SUBVERSION}\",\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        model=mega_classifier_a,\n",
    "        images=[train_images, validation_images],\n",
    "        epochs=EPOCHS,\n",
    "        call_backs=callbacks,\n",
    "        save_path=f\"./models/{MODEL_NAME}/{VERSION}/{VERSION}.{SUBVERSION}\",\n",
    "    )\n",
    "\n",
    "    model.save_training(\n",
    "        data=pd.DataFrame(history.history),\n",
    "        save_path=f\"./logs/{MODEL_NAME}/{VERSION}/{VERSION}.{SUBVERSION}/history_{VERSION}_{SUBVERSION}.csv\",\n",
    "    )\n",
    "\n",
    "    os.makedirs(f\"./reports/{MODEL_NAME}/{VERSION}/{VERSION}.{SUBVERSION}\", exist_ok=True)\n",
    "\n",
    "    accuracy_chart = graphics.create_training_accuracy_chart(\n",
    "        history_path=f\"./logs/{MODEL_NAME}/{VERSION}/{VERSION}.{SUBVERSION}/history_{VERSION}_{SUBVERSION}.csv\",\n",
    "        model_name=f\"{MODEL_NAME} {VERSION}.{SUBVERSION}\",\n",
    "    )\n",
    "    accuracy_chart.write_image(\n",
    "        f\"./reports/{MODEL_NAME}/{VERSION}/{VERSION}.{SUBVERSION}/train_accuracy_{VERSION}_{SUBVERSION}.png\")\n",
    "\n",
    "    loss_chart = graphics.create_training_loss_chart(\n",
    "        history_path=f\"./logs/{MODEL_NAME}/{VERSION}/{VERSION}.{SUBVERSION}/history_{VERSION}_{SUBVERSION}.csv\",\n",
    "        model_name=f\"{MODEL_NAME} {VERSION}.{SUBVERSION}\",\n",
    "    )\n",
    "    loss_chart.write_image(\n",
    "        f\"./reports/{MODEL_NAME}/{VERSION}/{VERSION}.{SUBVERSION}/train_loss_{VERSION}_{SUBVERSION}.png\")\n",
    "\n",
    "    results = model.evaluate_model(\n",
    "        model_path=f\"./models/{MODEL_NAME}/{VERSION}/{VERSION}.{SUBVERSION}\",\n",
    "        test_images=test_images,\n",
    "        custom_loss=True if SUBVERSION == 4 else False,\n",
    "    )\n",
    "\n",
    "    metric_names = history.model.metrics_names\n",
    "    evaluation_results = {(\"test_\" + name): value for name, value in zip(metric_names, results)}\n",
    "\n",
    "    model.save_evaluation(\n",
    "        data=pd.DataFrame([evaluation_results]),\n",
    "        save_path=f\"./logs/{MODEL_NAME}/{VERSION}/{VERSION}.{SUBVERSION}/evaluation_{VERSION}_{SUBVERSION}.csv\",\n",
    "    )\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    print(f\"Accuracy: {results[1]:.4%}\")\n",
    "    print(f\"Loss: {results[0]:.4%}\")\n",
    "    print(f\"AUC: {results[4]:.4%}\")\n",
    "    print(f\"Precision: {results[2]:.4%}\")\n",
    "    print(f\"Recall: {results[3]:.4%}\")\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    fpr, tpr, thresholds, roc_auc = model.roc_curve_model(\n",
    "        model_path=f\"./models/{MODEL_NAME}/{VERSION}/{VERSION}.{SUBVERSION}\",\n",
    "        test_images=test_images,\n",
    "        custom_loss=True if SUBVERSION == 4 else False,\n",
    "    )\n",
    "\n",
    "    roc_curve_chart = graphics.create_roc_curve_chart(\n",
    "        fpr=fpr,\n",
    "        tpr=tpr,\n",
    "        roc_auc=roc_auc,\n",
    "        model_name=f\"{MODEL_NAME} {VERSION}.{SUBVERSION}\",\n",
    "    )\n",
    "    roc_curve_chart.write_image(\n",
    "        f\"./reports/{MODEL_NAME}/{VERSION}/{VERSION}.{SUBVERSION}/roc_curve_{VERSION}_{SUBVERSION}.png\")\n",
    "\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    print(f\"OPTIMAL THRESHOLD: {optimal_threshold}\")\n",
    "\n",
    "    confusion_matrix = model.confusion_matrix_model(\n",
    "        model_path=f\"./models/{MODEL_NAME}/{VERSION}/{VERSION}.{SUBVERSION}\",\n",
    "        test_images=test_images,\n",
    "        optimal_threshold=optimal_threshold,\n",
    "        custom_loss=True if SUBVERSION == 4 else False,\n",
    "    )\n",
    "\n",
    "    confusion_matrix_chart = graphics.create_confusion_matrix_chart(\n",
    "        conf_matrix=confusion_matrix,\n",
    "        model_name=f\"{MODEL_NAME} {VERSION}.{SUBVERSION}\",\n",
    "    )\n",
    "    confusion_matrix_chart.write_image(\n",
    "        f\"./reports/{MODEL_NAME}/{VERSION}/{VERSION}.{SUBVERSION}/confusion_matrix_{VERSION}_{SUBVERSION}.png\")\n",
    "\n",
    "    evaluation_results[\"loss_function\"] = LOSS_NAME\n",
    "    all_results.append(pd.DataFrame([evaluation_results]))\n",
    "\n",
    "    SUBVERSION += 1\n",
    "\n",
    "final_results = pd.concat(all_results, ignore_index=True)\n",
    "final_results.to_csv(f\"./logs/{MODEL_NAME}/{VERSION}/loss_function_comparison_results.csv\", index=False)"
   ],
   "id": "4e745c49af91b5db",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TFG] *",
   "language": "python",
   "name": "conda-env-TFG-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
