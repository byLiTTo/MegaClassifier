{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "from keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import src.data.Dataset as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_paths = [\"/ai4eutils\", \"/CameraTraps\", \"/yolov5\"]\n",
    "python_path = os.environ.get(\"PYTHONPATH\", \"\")\n",
    "root_path = os.getcwd()\n",
    "\n",
    "for path in required_paths:\n",
    "    if not any(p.endswith(path) for p in python_path.split(\":\")):\n",
    "        python_path += f\":{root_path}/data/external{path}\"\n",
    "\n",
    "os.environ[\"PYTHONPATH\"] = python_path\n",
    "\n",
    "!echo \"PYTHONPATH: $PYTHONPATH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_DATASET_PATH = os.path.abspath(\"./data/raw/emptyNonEmptyDataset_ETL\")\n",
    "\n",
    "TRAIN_SAMPLES_CSV = os.path.abspath(\n",
    "    \"./data/raw/emptyNonEmptyDataset_ETL/28570Train.csv\"\n",
    ")\n",
    "VALIDATION_SAMPLES_CSV = os.path.abspath(\n",
    "    \"./data/raw/emptyNonEmptyDataset_ETL/28570Validation.csv\"\n",
    ")\n",
    "TEST_SAMPLES_CSV = os.path.abspath(\"./data/raw/emptyNonEmptyDataset_ETL/28570Test.csv\")\n",
    "\n",
    "print(f\"IMAGES_DATASET_PATH:    {IMAGES_DATASET_PATH}\")\n",
    "print(f\"TRAIN_SAMPLES_CSV:      {TRAIN_SAMPLES_CSV}\")\n",
    "print(f\"VALIDATION_SAMPLES_CSV: {VALIDATION_SAMPLES_CSV}\")\n",
    "print(f\"TEST_SAMPLES_CSV:       {TEST_SAMPLES_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe = dt.load_from_csv(TRAIN_SAMPLES_CSV)\n",
    "validation_dataframe = dt.load_from_csv(VALIDATION_SAMPLES_CSV)\n",
    "test_dataframe = dt.load_from_csv(TEST_SAMPLES_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe[\"file_name\"] = train_dataframe[\"file_name\"].apply(\n",
    "    lambda x: os.path.join(IMAGES_DATASET_PATH, x)\n",
    ")\n",
    "train_dataframe[\"binary_label\"] = train_dataframe[\"binary_label\"].astype(str)\n",
    "\n",
    "validation_dataframe[\"file_name\"] = validation_dataframe[\"file_name\"].apply(\n",
    "    lambda x: os.path.join(IMAGES_DATASET_PATH, x)\n",
    ")\n",
    "validation_dataframe[\"binary_label\"] = validation_dataframe[\"binary_label\"].astype(str)\n",
    "\n",
    "test_dataframe[\"file_name\"] = test_dataframe[\"file_name\"].apply(\n",
    "    lambda x: os.path.join(IMAGES_DATASET_PATH, x)\n",
    ")\n",
    "test_dataframe[\"binary_label\"] = test_dataframe[\"binary_label\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 25\n",
    "VERSION = 2.0\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tensorflow.keras.applications.vgg16.preprocess_input\n",
    ")\n",
    "normal_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tensorflow.keras.applications.vgg16.preprocess_input\n",
    ")\n",
    "\n",
    "train_images = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_dataframe,\n",
    "    x_col=\"file_name\",\n",
    "    y_col=\"binary_label\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "validation_images = normal_datagen.flow_from_dataframe(\n",
    "    dataframe=validation_dataframe,\n",
    "    x_col=\"file_name\",\n",
    "    y_col=\"binary_label\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "test_images = normal_datagen.flow_from_dataframe(\n",
    "    dataframe=test_dataframe,\n",
    "    x_col=\"file_name\",\n",
    "    y_col=\"binary_label\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def show_random_images_from_generator(generator, title):\n",
    "    # Obtener imágenes y etiquetas del generador\n",
    "    images, labels = next(generator)\n",
    "\n",
    "    # Revertir el preprocesamiento de VGG16\n",
    "    mean = np.array([103.939, 116.779, 123.68])  # Medias de ImageNet\n",
    "    images = images + mean  # Revertir la normalización por medias\n",
    "    images = images[..., ::-1]  # Convertir de BGR a RGB\n",
    "    images = np.clip(images, 0, 255)  # Asegurarse de que los valores estén en [0, 255]\n",
    "\n",
    "    # Visualizar las imágenes\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(min(10, len(images))):  # Mostrar un máximo de 10 imágenes\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(images[i].astype(\"uint8\"))  # Convertir a uint8 para visualización\n",
    "        plt.title(f\"Label: {int(labels[i])}\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Mostrar ejemplos de cada conjunto\n",
    "show_random_images_from_generator(train_images, \"Training Set\")\n",
    "show_random_images_from_generator(validation_images, \"Validation Set\")\n",
    "show_random_images_from_generator(test_images, \"Test Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tensorflow.keras.applications.VGG16(\n",
    "    weights=\"imagenet\", include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "# Construir el modelo básico\n",
    "model = tensorflow.keras.models.Sequential(\n",
    "    [\n",
    "        base_model,\n",
    "        tensorflow.keras.layers.Flatten(),\n",
    "        tensorflow.keras.layers.Dense(4096, activation=\"relu\"),\n",
    "        # tensorflow.keras.layers.Dropout(0.5),\n",
    "        tensorflow.keras.layers.Dense(4096, activation=\"relu\"),\n",
    "        # tensorflow.keras.layers.Dropout(0.5),\n",
    "        tensorflow.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=f\"VGG16_v.{VERSION}\",\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        \"binary_accuracy\",\n",
    "        Precision(name=\"presision\"),\n",
    "        Recall(name=\"recall\"),\n",
    "        AUC(name=\"auc\"),\n",
    "        TruePositives(name=\"tp\"),\n",
    "        FalsePositives(name=\"fp\"),\n",
    "        TrueNegatives(name=\"tn\"),\n",
    "        FalseNegatives(name=\"fn\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_images,\n",
    "    validation_data=validation_images,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[TensorBoard(log_dir=f\"./logs/VGG16/v.{VERSION}\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"./models/VGG16/VGG16_v.{VERSION}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv(f\"./logs/VGG16/v.{VERSION}/train_validation_history.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = history.model.evaluate(test_images)\n",
    "\n",
    "metric_names = history.model.metrics_names\n",
    "evaluation_results = {\n",
    "    (\"test_\" + name): value for name, value in zip(metric_names, results)\n",
    "}\n",
    "evaluation_df = pd.DataFrame([evaluation_results])\n",
    "evaluation_df.to_csv(f\"./logs/VGG16/v.{VERSION}/test_history.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
