{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import src.model as models\n",
    "from sklearn.metrics import auc, confusion_matrix, roc_curve\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.metrics import AUC, BinaryAccuracy, Precision, Recall\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import src.graphics as graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = \"2\"\n",
    "MODEL_BASE_NAME = \"MegaClassifier_a_MobileNetV2\"\n",
    "\n",
    "DATASET_CSV = os.path.abspath(\n",
    "    \"./data/processed/onlyDetectionsForTrain/onlyDetectionsForTrain.csv\"\n",
    ")\n",
    "DATASET_PATH = os.path.dirname(DATASET_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(DATASET_CSV, sep=\";\")\n",
    "dataset[\"file_name\"] = dataset[\"file_name\"].apply(\n",
    "    lambda x: os.path.join(DATASET_PATH, x)\n",
    ")\n",
    "dataset[\"binary_label\"] = dataset[\"binary_label\"].astype(str)\n",
    "\n",
    "train_dataset = dataset[dataset[\"subset\"] == \"train\"]\n",
    "validationtrain_dataset = dataset[dataset[\"subset\"] == \"validation\"]\n",
    "test_dataset = dataset[dataset[\"subset\"] == \"test\"]\n",
    "\n",
    "EPOCHS = 10\n",
    "IMAGE_SIZE = (224, 224)\n",
    "IMAGE_SHAPE = IMAGE_SIZE + (3,)\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZERS = {\n",
    "    \"Adam\": tf.keras.optimizers.legacy.Adam(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS = {\n",
    "    \"BinaryCrossentropy\": tf.keras.losses.BinaryCrossentropy(),\n",
    "    \"BinaryFocalCrossentropy\": tf.keras.losses.BinaryFocalCrossentropy(\n",
    "        alpha=0.25, gamma=2.0\n",
    "    ),\n",
    "    \"SigmoidFocalCrossEntropy\": tfa.losses.SigmoidFocalCrossEntropy(\n",
    "        alpha=0.25, gamma=2.0\n",
    "    ),\n",
    "    \"FocalLoss\": models.FocalLoss(alpha=0.25, gamma=2.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    BinaryAccuracy(name=\"accuracy\"),\n",
    "    Precision(name=\"precision\"),\n",
    "    Recall(name=\"recall\"),\n",
    "    AUC(name=\"auc\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17906 validated image filenames belonging to 2 classes.\n",
      "Found 4286 validated image filenames belonging to 2 classes.\n",
      "Found 4286 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 17:05:27.157956: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - ETA: 0s - loss: 0.2820 - accuracy: 0.8738 - precision: 0.8962 - recall: 0.9378 - auc: 0.9355"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 17:06:16.526180: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - 61s 213ms/step - loss: 0.2820 - accuracy: 0.8738 - precision: 0.8962 - recall: 0.9378 - auc: 0.9355 - val_loss: 0.2185 - val_accuracy: 0.9134 - val_precision: 0.9308 - val_recall: 0.9390 - val_auc: 0.9695\n",
      "Epoch 2/10\n",
      "280/280 [==============================] - 58s 206ms/step - loss: 0.2077 - accuracy: 0.9133 - precision: 0.9381 - recall: 0.9450 - auc: 0.9662 - val_loss: 0.1924 - val_accuracy: 0.9216 - val_precision: 0.9386 - val_recall: 0.9432 - val_auc: 0.9760\n",
      "Epoch 3/10\n",
      "280/280 [==============================] - 57s 203ms/step - loss: 0.1897 - accuracy: 0.9234 - precision: 0.9460 - recall: 0.9506 - auc: 0.9719 - val_loss: 0.1874 - val_accuracy: 0.9260 - val_precision: 0.9446 - val_recall: 0.9436 - val_auc: 0.9761\n",
      "Epoch 4/10\n",
      "280/280 [==============================] - 57s 204ms/step - loss: 0.1824 - accuracy: 0.9249 - precision: 0.9483 - recall: 0.9502 - auc: 0.9740 - val_loss: 0.1830 - val_accuracy: 0.9263 - val_precision: 0.9390 - val_recall: 0.9503 - val_auc: 0.9773\n",
      "Epoch 5/10\n",
      "280/280 [==============================] - 59s 209ms/step - loss: 0.1766 - accuracy: 0.9280 - precision: 0.9508 - recall: 0.9517 - auc: 0.9755 - val_loss: 0.1774 - val_accuracy: 0.9270 - val_precision: 0.9412 - val_recall: 0.9489 - val_auc: 0.9785\n",
      "Epoch 6/10\n",
      "280/280 [==============================] - 57s 204ms/step - loss: 0.1711 - accuracy: 0.9293 - precision: 0.9509 - recall: 0.9535 - auc: 0.9771 - val_loss: 0.1772 - val_accuracy: 0.9267 - val_precision: 0.9462 - val_recall: 0.9429 - val_auc: 0.9788\n",
      "Epoch 7/10\n",
      "280/280 [==============================] - 58s 207ms/step - loss: 0.1663 - accuracy: 0.9310 - precision: 0.9535 - recall: 0.9531 - auc: 0.9785 - val_loss: 0.1740 - val_accuracy: 0.9300 - val_precision: 0.9409 - val_recall: 0.9542 - val_auc: 0.9797\n",
      "Epoch 8/10\n",
      "280/280 [==============================] - 58s 206ms/step - loss: 0.1625 - accuracy: 0.9326 - precision: 0.9536 - recall: 0.9553 - auc: 0.9794 - val_loss: 0.1778 - val_accuracy: 0.9277 - val_precision: 0.9388 - val_recall: 0.9528 - val_auc: 0.9786\n",
      "Epoch 9/10\n",
      "280/280 [==============================] - 58s 206ms/step - loss: 0.1599 - accuracy: 0.9336 - precision: 0.9539 - recall: 0.9563 - auc: 0.9802 - val_loss: 0.1717 - val_accuracy: 0.9298 - val_precision: 0.9433 - val_recall: 0.9510 - val_auc: 0.9800\n",
      "Epoch 10/10\n",
      "280/280 [==============================] - 58s 206ms/step - loss: 0.1582 - accuracy: 0.9349 - precision: 0.9547 - recall: 0.9573 - auc: 0.9805 - val_loss: 0.1732 - val_accuracy: 0.9298 - val_precision: 0.9449 - val_recall: 0.9492 - val_auc: 0.9789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n",
      "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n",
      "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/litto/WORKSPACE/MegaClassifier/models/MegaClassifier_a_MobileNetV2/v2/v2.0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/litto/WORKSPACE/MegaClassifier/models/MegaClassifier_a_MobileNetV2/v2/v2.0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 12s 176ms/step - loss: 0.1636 - accuracy: 0.9351 - precision: 0.9485 - recall: 0.9538 - auc: 0.9818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 17:15:24.951657: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 12s 168ms/step\n",
      "\n",
      "\n",
      "\n",
      "Found 17906 validated image filenames belonging to 2 classes.\n",
      "Found 4286 validated image filenames belonging to 2 classes.\n",
      "Found 4286 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 17:15:38.346672: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - ETA: 0s - loss: 0.0877 - accuracy: 0.8929 - precision: 0.9237 - recall: 0.9287 - auc: 0.9466"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 17:16:27.507400: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - 62s 217ms/step - loss: 0.0877 - accuracy: 0.8929 - precision: 0.9237 - recall: 0.9287 - auc: 0.9466 - val_loss: 0.0583 - val_accuracy: 0.9090 - val_precision: 0.9140 - val_recall: 0.9520 - val_auc: 0.9711\n",
      "Epoch 2/10\n",
      "280/280 [==============================] - 59s 210ms/step - loss: 0.0524 - accuracy: 0.9178 - precision: 0.9431 - recall: 0.9459 - auc: 0.9693 - val_loss: 0.0500 - val_accuracy: 0.9239 - val_precision: 0.9413 - val_recall: 0.9439 - val_auc: 0.9761\n",
      "Epoch 3/10\n",
      "280/280 [==============================] - 58s 205ms/step - loss: 0.0485 - accuracy: 0.9228 - precision: 0.9469 - recall: 0.9487 - auc: 0.9737 - val_loss: 0.0492 - val_accuracy: 0.9267 - val_precision: 0.9562 - val_recall: 0.9319 - val_auc: 0.9773\n",
      "Epoch 4/10\n",
      "280/280 [==============================] - 58s 206ms/step - loss: 0.0455 - accuracy: 0.9262 - precision: 0.9489 - recall: 0.9513 - auc: 0.9766 - val_loss: 0.0529 - val_accuracy: 0.9232 - val_precision: 0.9641 - val_recall: 0.9182 - val_auc: 0.9761\n",
      "Epoch 5/10\n",
      "280/280 [==============================] - 58s 206ms/step - loss: 0.0440 - accuracy: 0.9276 - precision: 0.9503 - recall: 0.9519 - auc: 0.9781 - val_loss: 0.0486 - val_accuracy: 0.9281 - val_precision: 0.9524 - val_recall: 0.9383 - val_auc: 0.9780\n",
      "Epoch 6/10\n",
      "280/280 [==============================] - 58s 208ms/step - loss: 0.0432 - accuracy: 0.9321 - precision: 0.9538 - recall: 0.9543 - auc: 0.9790 - val_loss: 0.0502 - val_accuracy: 0.9242 - val_precision: 0.9269 - val_recall: 0.9612 - val_auc: 0.9786\n",
      "Epoch 7/10\n",
      "280/280 [==============================] - 58s 208ms/step - loss: 0.0418 - accuracy: 0.9317 - precision: 0.9541 - recall: 0.9534 - auc: 0.9803 - val_loss: 0.0476 - val_accuracy: 0.9293 - val_precision: 0.9421 - val_recall: 0.9517 - val_auc: 0.9790\n",
      "Epoch 8/10\n",
      "280/280 [==============================] - 58s 207ms/step - loss: 0.0413 - accuracy: 0.9337 - precision: 0.9536 - recall: 0.9568 - auc: 0.9809 - val_loss: 0.0486 - val_accuracy: 0.9256 - val_precision: 0.9595 - val_recall: 0.9267 - val_auc: 0.9785\n",
      "Epoch 9/10\n",
      "280/280 [==============================] - 59s 212ms/step - loss: 0.0404 - accuracy: 0.9338 - precision: 0.9549 - recall: 0.9556 - auc: 0.9815 - val_loss: 0.0485 - val_accuracy: 0.9284 - val_precision: 0.9338 - val_recall: 0.9598 - val_auc: 0.9795\n",
      "Epoch 10/10\n",
      "280/280 [==============================] - 59s 212ms/step - loss: 0.0403 - accuracy: 0.9347 - precision: 0.9551 - recall: 0.9565 - auc: 0.9817 - val_loss: 0.0492 - val_accuracy: 0.9286 - val_precision: 0.9470 - val_recall: 0.9450 - val_auc: 0.9774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n",
      "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/litto/WORKSPACE/MegaClassifier/models/MegaClassifier_a_MobileNetV2/v2/v2.1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/litto/WORKSPACE/MegaClassifier/models/MegaClassifier_a_MobileNetV2/v2/v2.1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 13s 183ms/step - loss: 0.0458 - accuracy: 0.9349 - precision: 0.9475 - recall: 0.9545 - auc: 0.9807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 17:25:43.125366: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 12s 169ms/step\n",
      "\n",
      "\n",
      "\n",
      "Found 17906 validated image filenames belonging to 2 classes.\n",
      "Found 4286 validated image filenames belonging to 2 classes.\n",
      "Found 4286 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 17:25:56.518780: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.8806 - precision: 0.9554 - recall: 0.8759 - auc: 0.9513"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 17:26:45.355457: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - 62s 217ms/step - loss: 0.0324 - accuracy: 0.8806 - precision: 0.9554 - recall: 0.8759 - auc: 0.9513 - val_loss: 0.0256 - val_accuracy: 0.9169 - val_precision: 0.9429 - val_recall: 0.9309 - val_auc: 0.9734\n",
      "Epoch 2/10\n",
      "280/280 [==============================] - 60s 213ms/step - loss: 0.0211 - accuracy: 0.9047 - precision: 0.9721 - recall: 0.8967 - auc: 0.9719 - val_loss: 0.0228 - val_accuracy: 0.8901 - val_precision: 0.9809 - val_recall: 0.8505 - val_auc: 0.9751\n",
      "Epoch 3/10\n",
      "280/280 [==============================] - 58s 208ms/step - loss: 0.0198 - accuracy: 0.9107 - precision: 0.9759 - recall: 0.9014 - auc: 0.9750 - val_loss: 0.0218 - val_accuracy: 0.8973 - val_precision: 0.9827 - val_recall: 0.8600 - val_auc: 0.9750\n",
      "Epoch 4/10\n",
      "280/280 [==============================] - 58s 206ms/step - loss: 0.0190 - accuracy: 0.9164 - precision: 0.9787 - recall: 0.9066 - auc: 0.9769 - val_loss: 0.0208 - val_accuracy: 0.9188 - val_precision: 0.9625 - val_recall: 0.9129 - val_auc: 0.9786\n",
      "Epoch 5/10\n",
      "280/280 [==============================] - 60s 216ms/step - loss: 0.0183 - accuracy: 0.9169 - precision: 0.9775 - recall: 0.9085 - auc: 0.9784 - val_loss: 0.0206 - val_accuracy: 0.9083 - val_precision: 0.9729 - val_recall: 0.8861 - val_auc: 0.9775\n",
      "Epoch 6/10\n",
      "280/280 [==============================] - 62s 221ms/step - loss: 0.0177 - accuracy: 0.9205 - precision: 0.9794 - recall: 0.9116 - auc: 0.9797 - val_loss: 0.0210 - val_accuracy: 0.9200 - val_precision: 0.9646 - val_recall: 0.9126 - val_auc: 0.9776\n",
      "Epoch 7/10\n",
      "280/280 [==============================] - 61s 216ms/step - loss: 0.0175 - accuracy: 0.9210 - precision: 0.9802 - recall: 0.9116 - auc: 0.9803 - val_loss: 0.0207 - val_accuracy: 0.9032 - val_precision: 0.9764 - val_recall: 0.8748 - val_auc: 0.9787\n",
      "Epoch 8/10\n",
      "280/280 [==============================] - 61s 217ms/step - loss: 0.0171 - accuracy: 0.9224 - precision: 0.9797 - recall: 0.9139 - auc: 0.9810 - val_loss: 0.0209 - val_accuracy: 0.9155 - val_precision: 0.9718 - val_recall: 0.8984 - val_auc: 0.9770\n",
      "Epoch 9/10\n",
      "280/280 [==============================] - 60s 213ms/step - loss: 0.0167 - accuracy: 0.9259 - precision: 0.9812 - recall: 0.9173 - auc: 0.9819 - val_loss: 0.0253 - val_accuracy: 0.8747 - val_precision: 0.9873 - val_recall: 0.8212 - val_auc: 0.9775\n",
      "Epoch 10/10\n",
      "280/280 [==============================] - 60s 214ms/step - loss: 0.0164 - accuracy: 0.9256 - precision: 0.9807 - recall: 0.9174 - auc: 0.9826 - val_loss: 0.0233 - val_accuracy: 0.9272 - val_precision: 0.9504 - val_recall: 0.9390 - val_auc: 0.9785\n",
      "INFO:tensorflow:Assets written to: /Users/litto/WORKSPACE/MegaClassifier/models/MegaClassifier_a_MobileNetV2/v2/v2.2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/litto/WORKSPACE/MegaClassifier/models/MegaClassifier_a_MobileNetV2/v2/v2.2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 12s 171ms/step - loss: 0.0220 - accuracy: 0.9321 - precision: 0.9537 - recall: 0.9432 - auc: 0.9813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 17:36:14.051143: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 11s 164ms/step\n",
      "\n",
      "\n",
      "\n",
      "Found 17906 validated image filenames belonging to 2 classes.\n",
      "Found 4286 validated image filenames belonging to 2 classes.\n",
      "Found 4286 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 17:36:26.977568: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.8978 - precision: 0.9281 - recall: 0.9310 - auc: 0.9574"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 17:37:15.761834: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - 61s 213ms/step - loss: 0.0183 - accuracy: 0.8978 - precision: 0.9281 - recall: 0.9310 - auc: 0.9574 - val_loss: 0.0132 - val_accuracy: 0.9176 - val_precision: 0.9493 - val_recall: 0.9249 - val_auc: 0.9733\n",
      "Epoch 2/10\n",
      "280/280 [==============================] - 59s 209ms/step - loss: 0.0124 - accuracy: 0.9199 - precision: 0.9440 - recall: 0.9478 - auc: 0.9723 - val_loss: 0.0131 - val_accuracy: 0.9195 - val_precision: 0.9618 - val_recall: 0.9147 - val_auc: 0.9752\n",
      "Epoch 3/10\n",
      "280/280 [==============================] - 60s 213ms/step - loss: 0.0115 - accuracy: 0.9243 - precision: 0.9481 - recall: 0.9494 - auc: 0.9760 - val_loss: 0.0122 - val_accuracy: 0.9265 - val_precision: 0.9497 - val_recall: 0.9386 - val_auc: 0.9771\n",
      "Epoch 4/10\n",
      "280/280 [==============================] - 57s 204ms/step - loss: 0.0111 - accuracy: 0.9280 - precision: 0.9519 - recall: 0.9506 - auc: 0.9779 - val_loss: 0.0116 - val_accuracy: 0.9300 - val_precision: 0.9418 - val_recall: 0.9531 - val_auc: 0.9798\n",
      "Epoch 5/10\n",
      "280/280 [==============================] - 60s 213ms/step - loss: 0.0109 - accuracy: 0.9304 - precision: 0.9522 - recall: 0.9537 - auc: 0.9786 - val_loss: 0.0123 - val_accuracy: 0.9263 - val_precision: 0.9599 - val_recall: 0.9274 - val_auc: 0.9783\n",
      "Epoch 6/10\n",
      "280/280 [==============================] - 59s 211ms/step - loss: 0.0105 - accuracy: 0.9326 - precision: 0.9535 - recall: 0.9554 - auc: 0.9800 - val_loss: 0.0120 - val_accuracy: 0.9274 - val_precision: 0.9504 - val_recall: 0.9394 - val_auc: 0.9786\n",
      "Epoch 7/10\n",
      "280/280 [==============================] - 60s 213ms/step - loss: 0.0102 - accuracy: 0.9333 - precision: 0.9537 - recall: 0.9562 - auc: 0.9812 - val_loss: 0.0121 - val_accuracy: 0.9258 - val_precision: 0.9294 - val_recall: 0.9609 - val_auc: 0.9797\n",
      "Epoch 8/10\n",
      "280/280 [==============================] - 58s 208ms/step - loss: 0.0101 - accuracy: 0.9337 - precision: 0.9550 - recall: 0.9552 - auc: 0.9816 - val_loss: 0.0125 - val_accuracy: 0.9251 - val_precision: 0.9261 - val_recall: 0.9637 - val_auc: 0.9796\n",
      "Epoch 9/10\n",
      "280/280 [==============================] - 59s 210ms/step - loss: 0.0099 - accuracy: 0.9354 - precision: 0.9551 - recall: 0.9575 - auc: 0.9822 - val_loss: 0.0124 - val_accuracy: 0.9277 - val_precision: 0.9609 - val_recall: 0.9284 - val_auc: 0.9783\n",
      "Epoch 10/10\n",
      "280/280 [==============================] - 60s 213ms/step - loss: 0.0099 - accuracy: 0.9369 - precision: 0.9565 - recall: 0.9582 - auc: 0.9823 - val_loss: 0.0134 - val_accuracy: 0.9221 - val_precision: 0.9190 - val_recall: 0.9676 - val_auc: 0.9788\n",
      "INFO:tensorflow:Assets written to: /Users/litto/WORKSPACE/MegaClassifier/models/MegaClassifier_a_MobileNetV2/v2/v2.3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/litto/WORKSPACE/MegaClassifier/models/MegaClassifier_a_MobileNetV2/v2/v2.3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 12s 175ms/step - loss: 0.0130 - accuracy: 0.9221 - precision: 0.9134 - recall: 0.9746 - auc: 0.9813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 17:46:35.443240: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 11s 164ms/step\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SUBVERSION = 0\n",
    "for LOSS_NAME, _ in LOSS.items():\n",
    "    LOGS_PATH = os.path.abspath(\n",
    "        f\"./logs/{MODEL_BASE_NAME}/v{VERSION}/v{VERSION}.{SUBVERSION}\"\n",
    "    )\n",
    "    MODELS_PATH = os.path.abspath(\n",
    "        f\"./models/{MODEL_BASE_NAME}/v{VERSION}/v{VERSION}.{SUBVERSION}\"\n",
    "    )\n",
    "    REPORTS_PATH = os.path.abspath(\n",
    "        f\"./reports/{MODEL_BASE_NAME}/v{VERSION}/v{VERSION}.{SUBVERSION}\"\n",
    "    )\n",
    "\n",
    "    MODEL_COMPLETE_NAME = f\"{MODEL_BASE_NAME} v{VERSION}.{SUBVERSION}\"\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "    )\n",
    "    train_images = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_dataset,\n",
    "        x_col=\"file_name\",\n",
    "        y_col=\"binary_label\",\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=True,\n",
    "        seed=SEED,\n",
    "    )\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "    )\n",
    "    validation_images = datagen.flow_from_dataframe(\n",
    "        dataframe=validationtrain_dataset,\n",
    "        x_col=\"file_name\",\n",
    "        y_col=\"binary_label\",\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=True,\n",
    "        seed=SEED,\n",
    "    )\n",
    "    test_images = datagen.flow_from_dataframe(\n",
    "        dataframe=test_dataset,\n",
    "        x_col=\"file_name\",\n",
    "        y_col=\"binary_label\",\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=False,\n",
    "        seed=SEED,\n",
    "    )\n",
    "\n",
    "    pretrained_model = tf.keras.applications.MobileNetV2(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        input_shape=IMAGE_SHAPE,\n",
    "    )\n",
    "    pretrained_model.trainable = False\n",
    "\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            pretrained_model,\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ],\n",
    "        name=f\"{MODEL_BASE_NAME}_v{VERSION}.{SUBVERSION}\",\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=OPTIMIZERS[\"Adam\"],\n",
    "        loss=LOSS[LOSS_NAME],\n",
    "        metrics=METRICS,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        train_images,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=validation_images,\n",
    "        callbacks=[TensorBoard(log_dir=LOGS_PATH)],\n",
    "    )\n",
    "\n",
    "    dataframe = pd.DataFrame(history.history)\n",
    "    history_path = os.path.join(LOGS_PATH, f\"history_v{VERSION}.{SUBVERSION}.csv\")\n",
    "    dataframe.to_csv(history_path, sep=\";\", index=False)\n",
    "\n",
    "    os.makedirs(REPORTS_PATH, exist_ok=True)\n",
    "    accuracy_chart = graphics.create_training_accuracy_chart(\n",
    "        history_path=history_path,\n",
    "        model_name=MODEL_COMPLETE_NAME,\n",
    "    )\n",
    "    accuracy_chart.write_image(f\"{REPORTS_PATH}/accuracy_v{VERSION}.{SUBVERSION}.png\")\n",
    "\n",
    "    loss_chart = graphics.create_training_loss_chart(\n",
    "        history_path=history_path,\n",
    "        model_name=MODEL_COMPLETE_NAME,\n",
    "    )\n",
    "    loss_chart.write_image(f\"{REPORTS_PATH}/loss_v{VERSION}.{SUBVERSION}.png\")\n",
    "\n",
    "    os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "    model.save(MODELS_PATH)\n",
    "\n",
    "    results = model.evaluate(test_images)\n",
    "    metric_names = history.model.metrics_names\n",
    "    evaluation_results = {\n",
    "        (\"test_\" + name): value for name, value in zip(metric_names, results)\n",
    "    }\n",
    "\n",
    "    evaluation = pd.DataFrame([evaluation_results])\n",
    "    evaluation.to_csv(\n",
    "        os.path.join(LOGS_PATH, f\"evaluation_v{VERSION}.{SUBVERSION}.csv\"),\n",
    "        sep=\";\",\n",
    "        index=False,\n",
    "    )\n",
    "\n",
    "    y_pred_prob = model.predict(test_images)\n",
    "    y_true = test_images.labels\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    roc_curve_chart = graphics.create_roc_curve_chart(\n",
    "        fpr=fpr,\n",
    "        tpr=tpr,\n",
    "        roc_auc=roc_auc,\n",
    "        model_name=MODEL_COMPLETE_NAME,\n",
    "    )\n",
    "    roc_curve_chart.write_image(f\"{REPORTS_PATH}/roc_curve_v{VERSION}.{SUBVERSION}.png\")\n",
    "\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "    # y_pred_prob = y_pred_prob.flatten()\n",
    "    y_pred_class = (y_pred_prob > optimal_threshold).astype(int)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred_class)\n",
    "    conf_matrix_text = [[str(value) for value in row] for row in conf_matrix]\n",
    "\n",
    "    # Crear el grÃ¡fico correctamente\n",
    "    confusion_matrix_chart = graphics.create_confusion_matrix_chart(\n",
    "        conf_matrix=conf_matrix,\n",
    "        conf_matrix_text=conf_matrix_text,\n",
    "        model_name=MODEL_COMPLETE_NAME,\n",
    "    )\n",
    "    confusion_matrix_chart.write_image(\n",
    "        f\"{REPORTS_PATH}/confusion_matrix_optimal_v{VERSION}.{SUBVERSION}.png\"\n",
    "    )\n",
    "\n",
    "    y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred_class)\n",
    "    conf_matrix_text = [[str(value) for value in row] for row in conf_matrix]\n",
    "\n",
    "    confusion_matrix_chart = graphics.create_confusion_matrix_chart(\n",
    "        conf_matrix=conf_matrix,\n",
    "        conf_matrix_text=conf_matrix_text,\n",
    "        model_name=MODEL_COMPLETE_NAME,\n",
    "    )\n",
    "    confusion_matrix_chart.write_image(\n",
    "        f\"{REPORTS_PATH}/confusion_matrix_v{VERSION}.{SUBVERSION}.png\"\n",
    "    )\n",
    "\n",
    "    SUBVERSION += 1\n",
    "    print(\"\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
