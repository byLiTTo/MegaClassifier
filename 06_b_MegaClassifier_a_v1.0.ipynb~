{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T11:49:43.624106Z",
     "start_time": "2025-02-25T11:49:41.461929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import src.graphics as graphics\n",
    "import src.model as model"
   ],
   "id": "3a510b979ca2e35a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T11:49:43.685096Z",
     "start_time": "2025-02-25T11:49:43.683360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_NAME = \"MegaClassifier_a\"\n",
    "VERSION = \"v1\"\n",
    "SUBVERSION = 0\n",
    "\n",
    "DATASET_CSV = os.path.abspath(\"./data/processed/onlyDetectionsForTrain/onlyDetectionsForTrain.csv\")\n",
    "DATASET_PATH = os.path.dirname(DATASET_CSV)"
   ],
   "id": "5d78f307f4361808",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T11:49:43.727474Z",
     "start_time": "2025-02-25T11:49:43.687357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = pd.read_csv(DATASET_CSV, sep=\";\")\n",
    "dataset['file_name'] = dataset['file_name'].apply(lambda x: os.path.join(DATASET_PATH, x))\n",
    "dataset['binary_label'] = dataset['binary_label'].astype(str)\n",
    "\n",
    "train_dataset = dataset[dataset['subset'] == \"train\"]\n",
    "validation_dataset = dataset[dataset['subset'] == \"validation\"]\n",
    "test_dataset = dataset[dataset['subset'] == \"test\"]"
   ],
   "id": "fdd385a1b5f4c70b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T11:49:43.738220Z",
     "start_time": "2025-02-25T11:49:43.736596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EPOCHS = 1\n",
    "# BATCH_SIZES = [16, 32, 64, 128]\n",
    "BATCH_SIZES = [16]"
   ],
   "id": "e772640c3899418e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T11:50:47.699821Z",
     "start_time": "2025-02-25T11:49:43.744256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_results = []\n",
    "for BATCH_SIZE in BATCH_SIZES:\n",
    "    print(f\"BATCH_SIZE: {BATCH_SIZE} ------------------------------------------------------------ \")\n",
    "\n",
    "    train_generator, other_generator = model.image_data_generator(version=VERSION)\n",
    "\n",
    "    train_images, validation_images, test_images = model.flow_from_dataframe(\n",
    "        datasets=[train_dataset, validation_dataset, test_dataset],\n",
    "        generators=[train_generator, other_generator],\n",
    "        batch_size=BATCH_SIZE,\n",
    "    )\n",
    "\n",
    "    mobilenet_v2 = model.load_pretrained(version=VERSION)\n",
    "\n",
    "    mega_classifier_a = model.compile_model(\n",
    "        version=VERSION,\n",
    "        pretrained_model=mobilenet_v2,\n",
    "        name=f\"{MODEL_NAME}_{VERSION}_{SUBVERSION}\")\n",
    "\n",
    "    callbacks = model.callbacks(\n",
    "        version=VERSION,\n",
    "        logs_path=f\"./logs/{MODEL_NAME}/{VERSION}/{VERSION}.{SUBVERSION}\",\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        version=VERSION,\n",
    "        model=mega_classifier_a,\n",
    "        images=[train_images, validation_images],\n",
    "        epochs=EPOCHS,\n",
    "        call_backs=callbacks,\n",
    "        save_path=f\"./models/{MODEL_NAME}/{VERSION}/{VERSION}.{SUBVERSION}\",\n",
    "    )\n",
    "\n",
    "    model.save_training(\n",
    "        data=pd.DataFrame(history.history),\n",
    "        save_path=f\"./logs/{MODEL_NAME}/{VERSION}/{VERSION}.{SUBVERSION}/history_{VERSION}_{SUBVERSION}.csv\",\n",
    "    )\n",
    "\n",
    "    accuracy_chart = graphics.create_training_accuracy_chart(\n",
    "        history_path=f\"./logs/{MODEL_NAME}/{VERSION}/{VERSION}.{SUBVERSION}/history_{VERSION}_{SUBVERSION}.csv\",\n",
    "        model_name=f\"{MODEL_NAME} {VERSION}.{SUBVERSION}\",\n",
    "    )\n",
    "    accuracy_chart.show()\n",
    "\n",
    "    loss_chart = graphics.create_training_loss_chart(\n",
    "        history_path=f\"./logs/{MODEL_NAME}/{VERSION}/{VERSION}.{SUBVERSION}/history_{VERSION}_{SUBVERSION}.csv\",\n",
    "        model_name=f\"{MODEL_NAME} {VERSION}.{SUBVERSION}\",\n",
    "    )\n",
    "    loss_chart.show()\n",
    "\n",
    "    results = model.evaluate_model(\n",
    "        model_path=f\"./models/{MODEL_NAME}/{VERSION}/{VERSION}.{SUBVERSION}\",\n",
    "        test_images=test_images,\n",
    "    )\n",
    "\n",
    "    metric_names = history.model.metrics_names\n",
    "    evaluation_results = {(\"test_\" + name): value for name, value in zip(metric_names, results)}\n",
    "\n",
    "    model.save_evaluation(\n",
    "        data=pd.DataFrame([evaluation_results]),\n",
    "        save_path=f\"./logs/{MODEL_NAME}/{VERSION}/{VERSION}.{SUBVERSION}/evaluation_{VERSION}_{SUBVERSION}.csv\",\n",
    "    )\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    print(f\"Accuracy: {results[1]:.4%}\")\n",
    "    print(f\"Loss: {results[0]:.4%}\")\n",
    "    print(f\"AUC: {results[4]:.4%}\")\n",
    "    print(f\"Precision: {results[2]:.4%}\")\n",
    "    print(f\"Recall: {results[3]:.4%}\")\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    fpr, tpr, thresholds, roc_auc = model.roc_curve_model(\n",
    "        model_path=f\"./models/{MODEL_NAME}/{VERSION}/{VERSION}.{SUBVERSION}\",\n",
    "        test_images=test_images,\n",
    "    )\n",
    "\n",
    "    roc_curve_chart = graphics.create_roc_curve_chart(\n",
    "        fpr=fpr,\n",
    "        tpr=tpr,\n",
    "        roc_auc=roc_auc,\n",
    "        model_name=f\"{MODEL_NAME} {VERSION}.{SUBVERSION}\",\n",
    "    )\n",
    "\n",
    "    roc_curve_chart.show()\n",
    "\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    print(\"OPTIMAL THRESHOLD: {optimal_threshold}\")\n",
    "\n",
    "    confusion_matrix = model.confusion_matrix_model(\n",
    "        model_path=f\"./models/{MODEL_NAME}/{VERSION}/{VERSION}.{SUBVERSION}\",\n",
    "        test_images=test_images,\n",
    "        optimal_threshold=optimal_threshold,\n",
    "    )\n",
    "\n",
    "    confusion_matrix_chart = graphics.create_confusion_matrix_chart(\n",
    "        conf_matrix=confusion_matrix,\n",
    "        model_name=f\"{MODEL_NAME} {VERSION}.{SUBVERSION}\",\n",
    "    )\n",
    "\n",
    "    confusion_matrix_chart.show()\n",
    "\n",
    "    evaluation_results[\"batch_size\"] = BATCH_SIZE\n",
    "    all_results.append(pd.DataFrame([evaluation_results]))\n",
    "\n",
    "    SUBVERSION += 1\n",
    "\n",
    "final_results = pd.concat(all_results, ignore_index=True)\n",
    "final_results.to_csv(f\"./logs/{MODEL_NAME}/{VERSION}/batch_comparison_results.csv\", index=False)"
   ],
   "id": "4e745c49af91b5db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE: 16 ------------------------------------------------------------ \n",
      "Found 17054 validated image filenames belonging to 2 classes.\n",
      "Found 4286 validated image filenames belonging to 2 classes.\n",
      "Found 4286 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 12:49:43.860658: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
      "2025-02-25 12:49:43.860686: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-02-25 12:49:43.860691: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-02-25 12:49:43.860715: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-02-25 12:49:43.860727: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 12:49:45.447172: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066/1066 [==============================] - ETA: 0s - loss: 0.2305 - accuracy: 0.9011 - precision: 0.9232 - recall: 0.9516 - auc: 0.9521"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 12:50:31.808948: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066/1066 [==============================] - 58s 54ms/step - loss: 0.2305 - accuracy: 0.9011 - precision: 0.9232 - recall: 0.9516 - auc: 0.9521 - val_loss: 0.1755 - val_accuracy: 0.9349 - val_precision: 0.9478 - val_recall: 0.9542 - val_auc: 0.9795\n",
      "\n",
      "\n",
      "\n",
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n",
      "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n",
      "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/MegaClassifier_a/v1/v1.0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/MegaClassifier_a/v1/v1.0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Saving training data...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda/envs/TFG/lib/python3.8/site-packages/pandas/core/indexes/base.py:3653\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3652\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3653\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3654\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/miniconda/envs/TFG/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/miniconda/envs/TFG/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'accuracy'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 39\u001B[0m\n\u001B[1;32m     25\u001B[0m history \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mfit(\n\u001B[1;32m     26\u001B[0m     version\u001B[38;5;241m=\u001B[39mVERSION,\n\u001B[1;32m     27\u001B[0m     model\u001B[38;5;241m=\u001B[39mmega_classifier_a,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     31\u001B[0m     save_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./models/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mMODEL_NAME\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mVERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mVERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mSUBVERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     32\u001B[0m )\n\u001B[1;32m     34\u001B[0m model\u001B[38;5;241m.\u001B[39msave_training(\n\u001B[1;32m     35\u001B[0m     data\u001B[38;5;241m=\u001B[39mpd\u001B[38;5;241m.\u001B[39mDataFrame(history\u001B[38;5;241m.\u001B[39mhistory),\n\u001B[1;32m     36\u001B[0m     save_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./logs/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mMODEL_NAME\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mVERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mVERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mSUBVERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/history_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mVERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mSUBVERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     37\u001B[0m )\n\u001B[0;32m---> 39\u001B[0m accuracy_chart \u001B[38;5;241m=\u001B[39m \u001B[43mgraphics\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_training_accuracy_chart\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhistory_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./logs/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mMODEL_NAME\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mVERSION\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mVERSION\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mSUBVERSION\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/history_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mVERSION\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mSUBVERSION\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     41\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mMODEL_NAME\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mVERSION\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mSUBVERSION\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     43\u001B[0m accuracy_chart\u001B[38;5;241m.\u001B[39mshow()\n\u001B[1;32m     45\u001B[0m loss_chart \u001B[38;5;241m=\u001B[39m graphics\u001B[38;5;241m.\u001B[39mcreate_training_loss_chart(\n\u001B[1;32m     46\u001B[0m     history_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./logs/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mMODEL_NAME\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mVERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mVERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mSUBVERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/history_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mVERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mSUBVERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     47\u001B[0m     model_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mMODEL_NAME\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mVERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mSUBVERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     48\u001B[0m )\n",
      "File \u001B[0;32m~/WORKSPACE/MegaClassifier/src/graphics.py:173\u001B[0m, in \u001B[0;36mcreate_training_accuracy_chart\u001B[0;34m(history_path, model_name)\u001B[0m\n\u001B[1;32m    170\u001B[0m history_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(history_path)\n\u001B[1;32m    172\u001B[0m fig_acc \u001B[38;5;241m=\u001B[39m go\u001B[38;5;241m.\u001B[39mFigure()\n\u001B[0;32m--> 173\u001B[0m fig_acc\u001B[38;5;241m.\u001B[39madd_trace(go\u001B[38;5;241m.\u001B[39mScatter(y\u001B[38;5;241m=\u001B[39m\u001B[43mhistory_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43maccuracy\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlines\u001B[39m\u001B[38;5;124m'\u001B[39m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraining Accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m    174\u001B[0m fig_acc\u001B[38;5;241m.\u001B[39madd_trace(go\u001B[38;5;241m.\u001B[39mScatter(y\u001B[38;5;241m=\u001B[39mhistory_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m], mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlines\u001B[39m\u001B[38;5;124m'\u001B[39m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mValidation Accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m    176\u001B[0m fig_acc\u001B[38;5;241m.\u001B[39mupdate_layout(\n\u001B[1;32m    177\u001B[0m     title\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining & Validation Accuracy - \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    178\u001B[0m     xaxis_title\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpochs\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    182\u001B[0m     height\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m500\u001B[39m\n\u001B[1;32m    183\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda/envs/TFG/lib/python3.8/site-packages/pandas/core/frame.py:3761\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3760\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3761\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3762\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3763\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/miniconda/envs/TFG/lib/python3.8/site-packages/pandas/core/indexes/base.py:3655\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3653\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3654\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3655\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3656\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3657\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3658\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3659\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3660\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'accuracy'"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TFG] *",
   "language": "python",
   "name": "conda-env-TFG-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
